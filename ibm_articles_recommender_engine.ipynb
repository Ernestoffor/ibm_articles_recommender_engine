{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Articles Recommender Engine for IBM Watson Studio Platform\n",
    " \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Exploratory Data Analysis](#Exploratory-Data-Analysis)<br>\n",
    "II. [Rank Based Recommendations](#Rank)<br>\n",
    "III. [User-User Based Collaborative Filtering](#User-User)<br>\n",
    "IV. [Content Based Recommendations](#Content-Recs)<br>\n",
    "V. [Matrix Factorization](#Matrix-Fact)<br>\n",
    "VI. [Extras & Concluding](#conclusions)\n",
    "\n",
    "Let's get started by importing the necessary libraries and reading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting progressbar2\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/19/afcfa7b88021a172f4f5308ca3cd95709c6ac39787caa720576e4b6cf6ba/progressbar2-3.55.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from progressbar2) (1.11.0)\n",
      "Collecting python-utils>=2.3.0 (from progressbar2)\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/04/78b4562436580e06ffc4518c051c3d9311d9947c8b47c7913867314887ba/python_utils-3.1.0-py2.py3-none-any.whl\n",
      "Installing collected packages: python-utils, progressbar2\n",
      "Successfully installed progressbar2-3.55.0 python-utils-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install progressbar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...   \n",
       "1      1314.0       healthcare python streaming application demo   \n",
       "2      1429.0         use deep learning for image classification   \n",
       "3      1338.0          ml optimization using cognitive assistant   \n",
       "4      1276.0          deploy your python model as a restful api   \n",
       "\n",
       "                                      email  \n",
       "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7  \n",
       "1  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b  \n",
       "2  b96a4f2e92d8572034b1e9b28f9ac673765cd074  \n",
       "3  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7  \n",
       "4  f01220c46fc92c6e6b161b1849de11faacd7ccb2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import project_tests as t\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from IPython.display import HTML\n",
    "import progressbar\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# Show df to get an idea of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content['article_id'] = df_content['article_id'].astype(str)\n",
    "type(df_content['article_id'][0])\n",
    "df['article_id'] = df['article_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">Part I : Exploratory Data Analysis</a>\n",
    "\n",
    "Use the dictionary and cells below to provide some insight into the descriptive statistics of the data.\n",
    "\n",
    "`1.` What is the distribution of how many articles a user interacts with in the dataset?  Provide a visual and descriptive statistics to assist with giving a look at the number of times each user interacts with an article.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45993</td>\n",
       "      <td>45976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>714</td>\n",
       "      <td>5148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>937</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  \\\n",
       "count                                        45993   \n",
       "unique                                         714   \n",
       "top     use deep learning for image classification   \n",
       "freq                                           937   \n",
       "\n",
       "                                           email  \n",
       "count                                      45976  \n",
       "unique                                      5148  \n",
       "top     2b6c0f514c2f2b04ad3c4583407dccd0810469ee  \n",
       "freq                                         364  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#df.email.value_counts()\n",
    "df[['title', 'email']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45993, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique titles or articles\n",
    "df['title'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id    45993\n",
       "email         45976\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_article = \n",
    "df[['article_id', 'email']].count()#.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['email'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_user_article_interactions = df['email'].value_counts().median()\n",
    "average_user_article_interactions = round(df['email'].value_counts().mean(), 1)\n",
    "max_num_of_user_article_interactions = df['email'].value_counts().max()\n",
    "df['email'].value_counts().max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the median and maximum number of user_article interactios below\n",
    "\n",
    "median_val = median_user_article_interactions  \n",
    "max_views_by_user = max_num_of_user_article_interactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% of individuals interact with 3.0 number of articles or fewer\n",
      "The maximum number of user-article interactions by any 1 user is 364.\n",
      "The average number of user-article interactions  is 8.9.\n"
     ]
    }
   ],
   "source": [
    "print(\"50% of individuals interact with {} number of articles or fewer\".format(median_val))\n",
    "print(\"The maximum number of user-article interactions by any 1 user is {}.\".format(max_views_by_user))\n",
    "print(\"The average number of user-article interactions  is {}.\".format(average_user_article_interactions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Explore and remove duplicate articles from the **df_content** dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content dataframe contains 0 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Find and explore duplicate articles\n",
    "num_of_duplicated_articles= df_content.duplicated().sum()\n",
    "print(\"The content dataframe contains {} duplicates\".format(num_of_duplicated_articles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique articles that have an interaction with a user is 714\n"
     ]
    }
   ],
   "source": [
    "# Remove any rows that have the same article_id - only keep the first\n",
    "df1 = df.drop_duplicates(subset=['article_id'], keep = 'first')\n",
    "print(f\"The number of unique articles that have an interaction with a user is {df1.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content1 = df_content.drop_duplicates(subset=['article_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1051"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content['article_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Finding answers to the following questions:\n",
    "\n",
    "**a.** The number of unique articles that have an interaction with a user.  \n",
    "**b.** The number of unique articles in the dataset (whether they have any interactions or not).<br>\n",
    "**c.** The number of unique users in the dataset. (excluding null values) <br>\n",
    "**d.** The number of user-article interactions in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5148 unique users in IBM platform.\n",
      "There are 714 unique articles that have at least one interaction.\n",
      "The number of unique articles on the IBM platform is 1051.\n",
      "The number of user-article interactions in the IBM platform is 45993\n"
     ]
    }
   ],
   "source": [
    "unique_articles_with_interactions = df['article_id'].nunique()\n",
    "unique_articles_in_IBM_platform = df_content['article_id'].nunique()\n",
    "unique_users = df['email'].nunique()\n",
    "user_article_interactions = df.shape[0]\n",
    "print(\"There are {} unique users in IBM platform.\".format(unique_users))\n",
    "print(\"There are {} unique articles that have at least one interaction.\"\\\n",
    "      .format(unique_articles_with_interactions))\n",
    "print(\"The number of unique articles on the IBM platform is {}.\"\\\n",
    "      .format(unique_articles_in_IBM_platform))\n",
    "print(\"The number of user-article interactions in the IBM platform is {}\"\\\n",
    "      .format(user_article_interactions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Use the cells below to find the most viewed **article_id**, as well as how often it was viewed.  After talking to the company leaders, the `email_mapper` function was deemed a reasonable way to map users to ids.  There were a small number of null values, and it was found that all of these null values likely belonged to a single user (which is how they are stored using the function below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_viewed_article_id = df.article_id.value_counts().index[0]\n",
    "number_of_times_most_viewed_articles_was_viewed = df.article_id.value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most viewed article in the dataset has id 1429.0 .\n",
      "The most viewed article in the dataset was viewed 937 times.\n"
     ]
    }
   ],
   "source": [
    "print(\"The most viewed article in the dataset has id {} .\".format(most_viewed_article_id))\n",
    "print(\"The most viewed article in the dataset was viewed {} times.\"\\\n",
    "      .format(number_of_times_most_viewed_articles_was_viewed ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_viewed_article_id = df.article_id.value_counts().index[0]\n",
    "max_views =  df.article_id.value_counts().max()   # The most viewed article in the dataset was viewed how many times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a081bd1d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a081a8be0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "info = {'details': ['unique_articles_with_interactions', 'unique_users', 'max_num_of_user_article_interactions'], \\\n",
    "        'val':[unique_articles_with_interactions, unique_users,max_num_of_user_article_interactions ]}\n",
    "dfp = pd.DataFrame(info)\n",
    "dfp.plot.barh(x = 'details', y = 'val', rot=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                                              title  user_id\n",
       "0     1430.0  using pixiedust for fast, flexible, and easier...        1\n",
       "1     1314.0       healthcare python streaming application demo        2\n",
       "2     1429.0         use deep learning for image classification        3\n",
       "3     1338.0          ml optimization using cognitive assistant        4\n",
       "4     1276.0          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def email_mapper():\n",
    "    \"\"\"\n",
    "    A function that maps the users emails to generate user ids:\n",
    "    \"\"\"\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5149"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                                              title  user_id\n",
       "0     1430.0  using pixiedust for fast, flexible, and easier...        1\n",
       "1     1314.0       healthcare python streaming application demo        2\n",
       "2     1429.0         use deep learning for image classification        3\n",
       "3     1338.0          ml optimization using cognitive assistant        4\n",
       "4     1276.0          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#email_encoded \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you have everything right here! Nice job!\n"
     ]
    }
   ],
   "source": [
    "user_article_interactions = df.shape[0]\n",
    "sol_1_dict = {\n",
    "    '`50% of individuals have _____ or fewer interactions.`': median_val,\n",
    "    '`The total number of user-article interactions in the dataset is ______.`': user_article_interactions,\n",
    "    '`The maximum number of user-article interactions by any 1 user is ______.`': max_views_by_user,\n",
    "    '`The most viewed article in the dataset was viewed _____ times.`': max_views,\n",
    "    '`The article_id of the most viewed article is ______.`': most_viewed_article_id,\n",
    "    '`The number of unique articles that have at least 1 rating ______.`': unique_articles_with_interactions,\n",
    "    '`The number of unique users in the dataset is ______`': unique_users,\n",
    "    '`The number of unique articles on the IBM platform`': unique_articles_in_IBM_platform \n",
    "}\n",
    "\n",
    "# Testing the dictionary against the solution\n",
    "t.sol_1_test(sol_1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "use deep learning for image classification                      937\n",
       "insights from new york car accident reports                     927\n",
       "visualize car data with brunel                                  671\n",
       "use xgboost, scikit-learn & ibm watson machine learning apis    643\n",
       "predicting churn with the spss random tree algorithm            627\n",
       "healthcare python streaming application demo                    614\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.value_counts()[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1429.0', '1330.0', '1431.0', '1427.0', '1364.0', '1314.0', '1293.0',\n",
       "       '1170.0', '1162.0', '1304.0',\n",
       "       ...\n",
       "       '1072.0', '1092.0', '1233.0', '974.0', '1113.0', '1119.0', '653.0',\n",
       "       '1202.0', '675.0', '1266.0'],\n",
       "      dtype='object', length=714)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.article_id.value_counts().index #[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Rank\">Part II: Rank-Based Recommendations</a>\n",
    "\n",
    "Unlike in the earlier lessons, we don't actually have ratings for whether a user liked an article or not.  We only know that a user has interacted with an article.  In these cases, the popularity of an article can really only be based on how often an article was interacted with.\n",
    "\n",
    "`1.` Fill in the function below to return the **n** top articles ordered with most interactions as the top. Test your function using the tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    # series of top n articles with titles as the index and frequency as values\n",
    "    top_articles = df.title.value_counts()[:n]\n",
    "    #convert the index to numpy array\n",
    "    top_articles = np.array(top_articles.index)\n",
    "    # Return the top article titles from df (not df_content)\n",
    "    return top_articles \n",
    "\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article ids \n",
    "    \n",
    "    '''\n",
    "    # Get a Series object with article ids as index and frequency as values\n",
    "    top_articles = df.article_id.value_counts()\n",
    "    # Convert the index to array and return first n values\n",
    "    \n",
    "    top_articles = np.array(top_articles.index)[:n]\n",
    "    \n",
    "    return top_articles # Return the top article ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use deep learning for image classification'\n",
      " 'insights from new york car accident reports'\n",
      " 'visualize car data with brunel'\n",
      " 'use xgboost, scikit-learn & ibm watson machine learning apis'\n",
      " 'predicting churn with the spss random tree algorithm'\n",
      " 'healthcare python streaming application demo'\n",
      " 'finding optimal locations of new store using decision optimization'\n",
      " 'apache spark lab, part 1: basic concepts'\n",
      " 'analyze energy consumption in buildings'\n",
      " 'gosales transactions for logistic regression model']\n",
      "['1429.0' '1330.0' '1431.0' '1427.0' '1364.0' '1314.0' '1293.0' '1170.0'\n",
      " '1162.0' '1304.0']\n"
     ]
    }
   ],
   "source": [
    "print(get_top_articles(10))\n",
    "print(get_top_article_ids(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top_5 looks like the solution list! Nice job.\n",
      "Your top_10 looks like the solution list! Nice job.\n",
      "Your top_20 looks like the solution list! Nice job.\n"
     ]
    }
   ],
   "source": [
    "# Test your function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of your three lists from above\n",
    "t.sol_2_test(get_top_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"User-User\">Part III: User-User Based Collaborative Filtering</a>\n",
    "\n",
    "\n",
    "`1.` Use the function below to reformat the **df** dataframe to be shaped with users as the rows and articles as the columns.  \n",
    "\n",
    "* Each **user** should only appear in each **row** once.\n",
    "\n",
    "\n",
    "* Each **article** should only show up in one **column**.  \n",
    "\n",
    "\n",
    "* **If a user has interacted with an article, then place a 1 where the user-row meets for that article-column**.  It does not matter how many times a user has interacted with the article, all entries where a user has interacted with an article should be a 1.  \n",
    "\n",
    "\n",
    "* **If a user has not interacted with an item, then place a zero where the user-row meets for that article-column**. \n",
    "\n",
    "Use the tests to make sure the basic structure of your matrix matches what is expected by the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    # The dimension of the matrix = n_users x n_articles\n",
    "        \n",
    "    user_item = df.groupby(['user_id', 'article_id'])['title'].count().unstack().notnull().astype(int)\n",
    "    \n",
    "    return user_item # return the user_item matrix \n",
    "\n",
    "user_item = create_user_item_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>1004.0</th>\n",
       "      <th>1006.0</th>\n",
       "      <th>1008.0</th>\n",
       "      <th>101.0</th>\n",
       "      <th>1014.0</th>\n",
       "      <th>1015.0</th>\n",
       "      <th>1016.0</th>\n",
       "      <th>...</th>\n",
       "      <th>977.0</th>\n",
       "      <th>98.0</th>\n",
       "      <th>981.0</th>\n",
       "      <th>984.0</th>\n",
       "      <th>985.0</th>\n",
       "      <th>986.0</th>\n",
       "      <th>990.0</th>\n",
       "      <th>993.0</th>\n",
       "      <th>996.0</th>\n",
       "      <th>997.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0  100.0  1000.0  1004.0  1006.0  1008.0  101.0  1014.0  1015.0  \\\n",
       "user_id                                                                         \n",
       "1             0      0       0       0       0       0      0       0       0   \n",
       "2             0      0       0       0       0       0      0       0       0   \n",
       "3             0      0       0       0       0       0      0       0       0   \n",
       "4             0      0       0       0       0       0      0       0       0   \n",
       "5             0      0       0       0       0       0      0       0       0   \n",
       "\n",
       "article_id  1016.0  ...    977.0  98.0  981.0  984.0  985.0  986.0  990.0  \\\n",
       "user_id             ...                                                     \n",
       "1                0  ...        0     0      1      0      0      0      0   \n",
       "2                0  ...        0     0      0      0      0      0      0   \n",
       "3                0  ...        1     0      0      0      0      0      0   \n",
       "4                0  ...        0     0      0      0      0      0      0   \n",
       "5                0  ...        0     0      0      0      0      0      0   \n",
       "\n",
       "article_id  993.0  996.0  997.0  \n",
       "user_id                          \n",
       "1               0      0      0  \n",
       "2               0      0      0  \n",
       "3               0      0      0  \n",
       "4               0      0      0  \n",
       "5               0      0      0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "\n",
       "                                       doc_full_name doc_status article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live          0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.shape\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1056"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a list and a dictionary to map the doc_description to numerical values\n",
    "desc_mapper = []\n",
    "doc_dic = dict()\n",
    "iters = 1\n",
    "for val in df_content['doc_description']:\n",
    "    if val not in doc_dic:\n",
    "        doc_dic[val] = iters\n",
    "        iters+=1\n",
    "    desc_mapper.append(doc_dic[val])\n",
    "len(desc_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1056"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a list and a dictionary to map the doc_full_name to numerical values\n",
    "name_mapper = []\n",
    "doc_dic = dict()\n",
    "iters = 1\n",
    "for val in df_content['doc_full_name']:\n",
    "    if val not in doc_dic:\n",
    "        doc_dic[val] = iters\n",
    "        iters+=1\n",
    "    name_mapper.append(doc_dic[val])\n",
    "len(name_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content['name'] = name_mapper\n",
    "df_content['description'] = desc_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>1004.0</th>\n",
       "      <th>1006.0</th>\n",
       "      <th>1008.0</th>\n",
       "      <th>101.0</th>\n",
       "      <th>1014.0</th>\n",
       "      <th>1015.0</th>\n",
       "      <th>1016.0</th>\n",
       "      <th>...</th>\n",
       "      <th>977.0</th>\n",
       "      <th>98.0</th>\n",
       "      <th>981.0</th>\n",
       "      <th>984.0</th>\n",
       "      <th>985.0</th>\n",
       "      <th>986.0</th>\n",
       "      <th>990.0</th>\n",
       "      <th>993.0</th>\n",
       "      <th>996.0</th>\n",
       "      <th>997.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0  100.0  1000.0  1004.0  1006.0  1008.0  101.0  1014.0  1015.0  \\\n",
       "user_id                                                                         \n",
       "1             0      0       0       0       0       0      0       0       0   \n",
       "2             0      0       0       0       0       0      0       0       0   \n",
       "3             0      0       0       0       0       0      0       0       0   \n",
       "4             0      0       0       0       0       0      0       0       0   \n",
       "5             0      0       0       0       0       0      0       0       0   \n",
       "\n",
       "article_id  1016.0  ...    977.0  98.0  981.0  984.0  985.0  986.0  990.0  \\\n",
       "user_id             ...                                                     \n",
       "1                0  ...        0     0      1      0      0      0      0   \n",
       "2                0  ...        0     0      0      0      0      0      0   \n",
       "3                0  ...        1     0      0      0      0      0      0   \n",
       "4                0  ...        0     0      0      0      0      0      0   \n",
       "5                0  ...        0     0      0      0      0      0      0   \n",
       "\n",
       "article_id  993.0  996.0  997.0  \n",
       "user_id                          \n",
       "1               0      0      0  \n",
       "2               0      0      0  \n",
       "3               0      0      0  \n",
       "4               0      0      0  \n",
       "5               0      0      0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['user_id', 'article_id'])['title'].count().unstack().notnull().astype(int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item.sum(axis=1)[4] \n",
    "df.article_id = df.article_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have passed our quick tests!  Please proceed!\n"
     ]
    }
   ],
   "source": [
    "## Tests:Checking the correctness of the codes\n",
    "assert user_item.shape[0] == 5149, \"Oops!  The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"Oops!  The number of articles in the user-article matrix doesn't look right.\"\n",
    "assert user_item.sum(axis=1)[1] == 36, \"Oops!  The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"You have passed our quick tests!  Please proceed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_item.dot(np.transpose(user_item))\n",
    "user_item.sum(axis=1).max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>1004.0</th>\n",
       "      <th>1006.0</th>\n",
       "      <th>1008.0</th>\n",
       "      <th>101.0</th>\n",
       "      <th>1014.0</th>\n",
       "      <th>1015.0</th>\n",
       "      <th>1016.0</th>\n",
       "      <th>...</th>\n",
       "      <th>977.0</th>\n",
       "      <th>98.0</th>\n",
       "      <th>981.0</th>\n",
       "      <th>984.0</th>\n",
       "      <th>985.0</th>\n",
       "      <th>986.0</th>\n",
       "      <th>990.0</th>\n",
       "      <th>993.0</th>\n",
       "      <th>996.0</th>\n",
       "      <th>997.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0  100.0  1000.0  1004.0  1006.0  1008.0  101.0  1014.0  1015.0  \\\n",
       "user_id                                                                         \n",
       "1             0      0       0       0       0       0      0       0       0   \n",
       "2             0      0       0       0       0       0      0       0       0   \n",
       "\n",
       "article_id  1016.0  ...    977.0  98.0  981.0  984.0  985.0  986.0  990.0  \\\n",
       "user_id             ...                                                     \n",
       "1                0  ...        0     0      1      0      0      0      0   \n",
       "2                0  ...        0     0      0      0      0      0      0   \n",
       "\n",
       "article_id  993.0  996.0  997.0  \n",
       "user_id                          \n",
       "1               0      0      0  \n",
       "2               0      0      0  \n",
       "\n",
       "[2 rows x 714 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_df = pd.DataFrame(user_item)\n",
    "idx1 = 12\n",
    "#user_item_df[user_item_df['user_id'] == idx1]\n",
    "user_item_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 0\n",
    "for x in user_item_df.iloc[2, :]:\n",
    "    if x ==1:\n",
    "       num+=1\n",
    "num1 = []\n",
    "y = user_item_df.iloc[2, :]\n",
    "for i in y.index:\n",
    "    if y[i] == 1:\n",
    "        num1.append(i)\n",
    "num\n",
    "#y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Complete the function below which should take a user_id and provide an ordered list of the most similar users to that user (from most similar to least similar).  The returned result should not contain the provided user_id, as we know that each user is similar to him/herself. Because the results for each user here are binary, it (perhaps) makes sense to compute similarity as the dot product of two users. \n",
    "\n",
    "Use the tests to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_users(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    \n",
    "    '''\n",
    "    # convert the user_item matrix  to dataframe\n",
    "    user_item_df = pd.DataFrame(user_item)\n",
    "    # perform dot product between user_item_df and itself at the user_id\n",
    "    similar_users = user_item_df.dot(user_item_df.iloc[user_id])\n",
    "    \n",
    "    \n",
    "    # sort similar_users \n",
    "    similar_users  = similar_users.sort_values(ascending = False)\n",
    "\n",
    "    \n",
    "    # remove the user's own  id\n",
    "    similar_users = similar_users.drop(user_id)\n",
    "    # create list of just the user ids using the Series index\n",
    "    most_similar_users = list(similar_users.index)\n",
    "       \n",
    "    return most_similar_users # return a list of the users in order from most to least similar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 1\n",
    "a = user_item.dot(user_item.iloc[user_id]).sort_values(ascending=False)\n",
    "b = find_similar_users(1)\n",
    "a = a.drop(user_id)\n",
    "a = list(a.index)\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [2, 3764, 49, 98, 3697, 10, 2982, 21, 3782, 290]\n",
      "The 5 most similar users to user 3933 are: [3934, 49, 126, 2742, 1062]\n",
      "The 3 most similar users to user 46 are: [4527, 120, 3419]\n"
     ]
    }
   ],
   "source": [
    "# Spot check of the function\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now that we have a function that provides the most similar users to each user, we will want to use these users to find articles to recommend.  The functions below would return the articles we would recommend to each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    # initialize an empty list\n",
    "    article_names = [df[df['article_id'] == idx]['title'].values[0] for idx in article_ids]\n",
    "        \n",
    "    \n",
    "    return article_names # Return the article names associated with list of article ids\n",
    "\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column in df)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    #Get the article ids at the user_id and transpose the result\n",
    "    #article_ids = user_item[user_item.index==user_id].isin([1]).astype(int).T\n",
    "    \n",
    "    # Get the article ids of the articles the user actually interacted with as a list\n",
    "    #article_ids = article_ids[article_ids[user_id] == 1].index.tolist()\n",
    "    article_ids = user_item.loc[user_id, :][user_item.loc[user_id, :].values == 1].index.astype('str')\n",
    "    article_ids = list(article_ids)\n",
    "    # Use the get_article_names function to get the article names\n",
    "    article_names = get_article_names(article_ids)\n",
    "    # return the ids and names\n",
    "    return article_ids, article_names \n",
    "\n",
    "\n",
    "def user_user_recs(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    '''\n",
    "    most_similar_user_ids = find_similar_users(user_id)\n",
    "    recs = np.array([])\n",
    "    ids_articles_seen_by_user, _ = get_user_articles(user_id)\n",
    "    for idx in most_similar_user_ids:\n",
    "        # article ids interacted with by each similar user\n",
    "        similar_user_articles = get_user_articles(idx)[0]\n",
    "        # Get articles to recommend\n",
    "        rec_new = np.setdiff1d(similar_user_articles, ids_articles_seen_by_user, assume_unique=True)\n",
    "        recs=  np.unique(np.concatenate([rec_new, recs], axis=0))\n",
    "        if len(recs) > m-1:\n",
    "            break\n",
    "    \n",
    "    return recs[:m] # return your recommendations for this user_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how to choose a project to practice data science',\n",
       " '7 types of job profiles that makes you a data scientist',\n",
       " 'using deep learning to reconstruct high-resolution audio',\n",
       " 'data tidying in data science experience',\n",
       " 'a comparison of logistic regression and naive bayes ',\n",
       " 'access mysql with r',\n",
       " '520    using notebooks with pixiedust for fast, flexi...\\nName: title, dtype: object',\n",
       " 'pixiedust: magic for your python notebook',\n",
       " 'airbnb data for analytics: new york city reviews',\n",
       " 'practical tutorial on random forest and parameter tuning in r']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Results . Return 10 recommendations for user 1\n",
    "get_article_names(user_user_recs(1, 10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you passed all of our tests!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Testing the functions here \n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"If this is all you see, you passed all of our tests!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Now we are going to improve the consistency of the **user_user_recs** function from above.  \n",
    "\n",
    "* Instead of arbitrarily choosing when we obtain users who are all the same closeness to a given user - choose the users that have the most total article interactions before choosing those with fewer article interactions.\n",
    "\n",
    "\n",
    "* Instead of arbitrarily choosing articles from the user where the number of recommended articles starts below m and ends exceeding m, choose articles with the articles with the most total interactions before choosing those with fewer total interactions. This ranking should be  what would be obtained from the **top_articles** function we  wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "                    \n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where \n",
    "                    highest of each is higher in the dataframe\n",
    "     \n",
    "    '''\n",
    "    # Drop the user user_id row from ther user_item matrix\n",
    "    #user_item1 = user_item.copy().drop(user_id)\n",
    "    # Get the user_ids as matrix and assign it to the neighbors ids\n",
    "    users_list = user_item.index.tolist()\n",
    "    neighbors_user_id = [user for user in users_list if user!=user_id]\n",
    "    \n",
    "    \n",
    "    neighbors_df = pd.DataFrame(columns = ['neighbor_id', 'similarity', 'num_interactions'])\n",
    "    #iterate through list to calculate dot product and append to similarity dataframe\n",
    "    for k in neighbors_user_id:\n",
    "        similarity = np.dot(user_item.loc[k,:],user_item.loc[user_id,:])\n",
    "        num_interactions = user_item.loc[k,:].sum()\n",
    "        s = pd.DataFrame([[k, similarity, num_interactions]], columns = [\"neighbor_id\", \"similarity\", \"num_interactions\"])\n",
    "        neighbors_df = neighbors_df.append(s, ignore_index = True) \n",
    "    neighbors_df = neighbors_df.sort_values(by = ['similarity', 'num_interactions'], ascending=False)\n",
    "    # Return the dataframe \n",
    "    return neighbors_df \n",
    "\n",
    "\n",
    "def user_user_recs_part2(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions \n",
    "    before choosing those with fewer total interactions. \n",
    "   \n",
    "    '''\n",
    "    # Get the neighbors sorted by number of interactions with article\n",
    "    neighbors_ids = list(get_top_sorted_users(user_id).neighbor_id)\n",
    "    recs = []\n",
    "    \n",
    "    ids_articles_seen_by_user, article_names = get_user_articles(user_id)\n",
    "    for idx in neighbors_ids:\n",
    "        # article ids interacted with by each similar user\n",
    "        similar_user_articles_id, similar_user_articles_names= get_user_articles(idx)\n",
    "        # Get articles to recommend\n",
    "        rec_new = np.setdiff1d(np.array(similar_user_articles_id), np.array(ids_articles_seen_by_user))\n",
    "        recs1=  np.setdiff1d(rec_new, np.array(recs))\n",
    "        recs1 = list(recs1)\n",
    "        recs.extend(recs1)\n",
    "        if len(recs) > m-1:\n",
    "            break \n",
    "    recs = recs[:m]       \n",
    "    rec_names = get_article_names(recs)\n",
    "    \n",
    "    \n",
    "    return recs, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 64.1 ms, total: 11.2 s\n",
      "Wall time: 22.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbor_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>3933</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>3782</td>\n",
       "      <td>17</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>203</td>\n",
       "      <td>15</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>4459</td>\n",
       "      <td>15</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neighbor_id similarity num_interactions\n",
       "3931        3933         35               35\n",
       "21            23         17              135\n",
       "3780        3782         17              135\n",
       "201          203         15               96\n",
       "4457        4459         15               96"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%time get_top_sorted_users(1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 recommendations for user 20 are the following article ids:\n",
      "['1014.0', '1059.0', '109.0', '111.0', '1157.0', '1162.0', '1164.0', '1172.0', '1186.0', '12.0']\n",
      "\n",
      "The top 10 recommendations for user 20 are the following article names:\n",
      "['1448    i ranked every intro to data science course on...\\nName: title, dtype: object', 'airbnb data for analytics: amsterdam calendar', 'tensorflow quick tips', 'tidy up your jupyter notebooks with scripts', 'airbnb data for analytics: washington d.c. listings', 'analyze energy consumption in buildings', 'analyze open data sets with pandas dataframes', 'apache spark lab, part 3: machine learning', 'connect to db2 warehouse on cloud and db2 using scala', 'timeseries data analysis of iot events by using jupyter notebook']\n",
      "CPU times: user 11.7 s, sys: 83.8 ms, total: 11.8 s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "rec_ids, rec_names = user_user_recs_part2(20, 10)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3933\n",
      "3910\n",
      "CPU times: user 22.6 s, sys: 234 ms, total: 22.8 s\n",
      "Wall time: 45.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(get_top_sorted_users(1)['neighbor_id'].iloc[0])\n",
    "print(get_top_sorted_users(131)['neighbor_id'].iloc[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbor_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>3870</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>3782</td>\n",
       "      <td>39</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>203</td>\n",
       "      <td>33</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>4459</td>\n",
       "      <td>33</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>3697</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>29</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3762</th>\n",
       "      <td>3764</td>\n",
       "      <td>29</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>3910</td>\n",
       "      <td>25</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>242</td>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>4932</td>\n",
       "      <td>24</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>3740</td>\n",
       "      <td>23</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>23</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>3596</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>290</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neighbor_id similarity num_interactions\n",
       "3868        3870         74               75\n",
       "3780        3782         39              135\n",
       "22            23         38              135\n",
       "201          203         33               96\n",
       "4457        4459         33               96\n",
       "48            49         29              101\n",
       "3695        3697         29              100\n",
       "97            98         29               97\n",
       "3762        3764         29               97\n",
       "3908        3910         25               60\n",
       "240          242         25               59\n",
       "39            40         24               52\n",
       "4930        4932         24               52\n",
       "3738        3740         23               71\n",
       "57            58         23               70\n",
       "3594        3596         23               59\n",
       "51            52         23               58\n",
       "288          290         22               58"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_sorted_users(131).iloc[0:18] #['neighbor_id']."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Using the functions from above to correctly fill in the solutions to the dictionary below.  Then test the dictionary against the solution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests with a dictionary of results\n",
    "# The code to answer each question below.\n",
    "user1_most_sim =  get_top_sorted_users(1)['neighbor_id'].values[0]   # Find the user that is most similar to user 1 \n",
    "user131_10th_sim = get_top_sorted_users(131)['neighbor_id'].values[10]     # Find the 10th most similar user to user 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This all looks good!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "## Dictionary Test Here\n",
    "sol_5_dict = {\n",
    "    'The user that is most similar to user 1.': user1_most_sim, \n",
    "    'The user that is the 10th most similar to user 131': user131_10th_sim,\n",
    "}\n",
    "\n",
    "t.sol_5_test(sol_5_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` If we were given a new user, which of the above functions would you be able to use to make recommendations?    Can we think of a better way we might make recommendations? Some explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When presented with a new user not among the existing users, recommending the most popular articles using both the **get_top_articles(n, df=df)** and the **get_top_article_ids(n, df=df)** functions based on the number of number of times  users and articles' interacted would be ideal. However, this approach is not optimal because not all users are interested in the most popular articles. \n",
    "A better approach would be to make recommendations based on the type of articles they might be interested in via content based recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7.` Using the existing functions, provide the top 10 recommended articles we would provide for a new user below.  We can test your function against existing solution to make sure we are correct with how we might make a recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "new_user_recs = get_top_article_ids(10, df=df)\n",
    "assert set(new_user_recs) == set(['1314.0','1429.0','1293.0','1427.0','1162.0','1364.0','1304.0','1170.0','1431.0','1330.0']), \"Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\n",
    "\n",
    "print(\"That's right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['use deep learning for image classification',\n",
       "       'insights from new york car accident reports',\n",
       "       'visualize car data with brunel',\n",
       "       'use xgboost, scikit-learn & ibm watson machine learning apis',\n",
       "       'predicting churn with the spss random tree algorithm',\n",
       "       'healthcare python streaming application demo',\n",
       "       'finding optimal locations of new store using decision optimization',\n",
       "       'apache spark lab, part 1: basic concepts',\n",
       "       'analyze energy consumption in buildings',\n",
       "       'gosales transactions for logistic regression model'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user = '0.0'\n",
    "\n",
    "# What would be the recommendations be for this new user '0.0'?  As a new user, they have no observed articles.\n",
    "# A list of the top 10 articles to be recommended to the new user are\n",
    "new_user_recs = get_top_articles(10) \n",
    "\n",
    "new_user_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Content-Recs\">Part IV: Content Based Recommendations </a>\n",
    "\n",
    "Another method we might use to make recommendations is to perform a ranking of the highest ranked articles associated with some term.  We will consider content to be the  **doc_description**.  There isn't one way to create a content based recommendation, especially considering that each of **doc_full_name, doc_body and doc_description** columns hold content related information.  \n",
    "\n",
    "`1.` The functions below are used to create a content based recommender.  Since there isn't one right answer for this recommendation tactic, no test functions are provided.  The input values are currently set with one idea in mind that we may use to make content based recommendations. There is a lot of flexibility in how one might make these recommendations. One additional idea is that we might want to choose the most popular recommendations that meet the desired 'content criteria', but we will go ahead with content based on the **doc_description**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the datatype of article_id\n",
    "df.article_id = df['article_id'].astype('float')\n",
    "df.article_id = df['article_id'].astype('int')\n",
    "df_content.article_id = df_content['article_id'].astype('float')\n",
    "df_content.article_id = df_content['article_id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4258"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the df and df_content dataframes\n",
    "big_df = df.merge(df_content, how='left', on='article_id')\n",
    "\n",
    "# Percentage of null values\n",
    "big_df.isnull().sum().sum()/np.product(big_df.shape)\n",
    "articles_not_in_content_df = big_df[big_df.doc_body.isnull() == True]['article_id']#.unique()\n",
    "articles_not_in_content_df.shape\n",
    "# Drop null values\n",
    "df_new1 = big_df.dropna()\n",
    "df_new1['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>8</td>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>Data Science Experience (DSX) is a unified ana...</td>\n",
       "      <td>Upload Files to IBM Data Science Experience Us...</td>\n",
       "      <td>Live</td>\n",
       "      <td>594.0</td>\n",
       "      <td>577.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id  \\\n",
       "7         593  upload files to ibm data science experience us...        8   \n",
       "\n",
       "                                            doc_body  \\\n",
       "7  Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "7  Data Science Experience (DSX) is a unified ana...   \n",
       "\n",
       "                                       doc_full_name doc_status   name  \\\n",
       "7  Upload Files to IBM Data Science Experience Us...       Live  594.0   \n",
       "\n",
       "   description  \n",
       "7        577.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>999.0</th>\n",
       "      <th>1002.0</th>\n",
       "      <th>1004.0</th>\n",
       "      <th>1011.0</th>\n",
       "      <th>1015.0</th>\n",
       "      <th>1016.0</th>\n",
       "      <th>1017.0</th>\n",
       "      <th>1020.0</th>\n",
       "      <th>1021.0</th>\n",
       "      <th>1023.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>8</td>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>Data Science Experience (DSX) is a unified ana...</td>\n",
       "      <td>Upload Files to IBM Data Science Experience Us...</td>\n",
       "      <td>Live</td>\n",
       "      <td>594.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>993</td>\n",
       "      <td>configuring the apache spark sql context</td>\n",
       "      <td>11</td>\n",
       "      <td>* Home\\r\\n * Community\\r\\n * Projects\\r\\n * Bl...</td>\n",
       "      <td>The Apache Spark website documents the propert...</td>\n",
       "      <td>Configuring the Apache Spark SQL Context</td>\n",
       "      <td>Live</td>\n",
       "      <td>994.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>got zip code data? prep it for analytics. â€“ ib...</td>\n",
       "      <td>12</td>\n",
       "      <td>Raj Singh Blocked Unblock Follow Following Dev...</td>\n",
       "      <td>Who are those people lurking behind the statis...</td>\n",
       "      <td>Got zip code data? Prep it for analytics. â€“ IB...</td>\n",
       "      <td>Live</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>542</td>\n",
       "      <td>getting started with python</td>\n",
       "      <td>14</td>\n",
       "      <td>Getting started with python. This book is inte...</td>\n",
       "      <td>This book is intended for anyone who works wit...</td>\n",
       "      <td>Getting started with Python</td>\n",
       "      <td>Live</td>\n",
       "      <td>543.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>timeseries data analysis of iot events by usin...</td>\n",
       "      <td>11</td>\n",
       "      <td>Skip to main content IBM developerWorks / Deve...</td>\n",
       "      <td>This recipe showcases how one can analyze the ...</td>\n",
       "      <td>Timeseries Data Analysis of IoT events by usin...</td>\n",
       "      <td>Live</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 429 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                              title  user_id  \\\n",
       "7          593  upload files to ibm data science experience us...        8   \n",
       "10         993           configuring the apache spark sql context       11   \n",
       "11          14  got zip code data? prep it for analytics. â€“ ib...       12   \n",
       "15         542                        getting started with python       14   \n",
       "16          12  timeseries data analysis of iot events by usin...       11   \n",
       "\n",
       "                                             doc_body  \\\n",
       "7   Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "10  * Home\\r\\n * Community\\r\\n * Projects\\r\\n * Bl...   \n",
       "11  Raj Singh Blocked Unblock Follow Following Dev...   \n",
       "15  Getting started with python. This book is inte...   \n",
       "16  Skip to main content IBM developerWorks / Deve...   \n",
       "\n",
       "                                      doc_description  \\\n",
       "7   Data Science Experience (DSX) is a unified ana...   \n",
       "10  The Apache Spark website documents the propert...   \n",
       "11  Who are those people lurking behind the statis...   \n",
       "15  This book is intended for anyone who works wit...   \n",
       "16  This recipe showcases how one can analyze the ...   \n",
       "\n",
       "                                        doc_full_name doc_status   name  \\\n",
       "7   Upload Files to IBM Data Science Experience Us...       Live  594.0   \n",
       "10           Configuring the Apache Spark SQL Context       Live  994.0   \n",
       "11  Got zip code data? Prep it for analytics. â€“ IB...       Live   15.0   \n",
       "15                        Getting started with Python       Live  543.0   \n",
       "16  Timeseries Data Analysis of IoT events by usin...       Live   13.0   \n",
       "\n",
       "    description  3.0   ...    999.0  1002.0  1004.0  1011.0  1015.0  1016.0  \\\n",
       "7         577.0    0   ...        0       0       0       0       0       0   \n",
       "10        967.0    0   ...        0       0       0       0       0       0   \n",
       "11         15.0    0   ...        0       0       0       0       0       0   \n",
       "15        527.0    0   ...        0       0       0       0       0       0   \n",
       "16         13.0    0   ...        0       0       0       0       0       0   \n",
       "\n",
       "    1017.0  1020.0  1021.0  1023.0  \n",
       "7        0       0       0       0  \n",
       "10       0       0       0       0  \n",
       "11       0       0       0       0  \n",
       "15       0       0       0       0  \n",
       "16       0       0       0       0  \n",
       "\n",
       "[5 rows x 429 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dummy values for the description column and concatenate with the df_new1\n",
    "df2=  pd.concat([df_new1, pd.get_dummies(df_new1['description'], prefix_sep='_', drop_first=True)], axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the content from the description dummy variables\n",
    "article_content = np.array(df2.iloc[:, 9:])\n",
    "article_content_T = np.transpose(article_content)\n",
    "article_product = article_content.dot(article_content_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the article_product as a pickle file\n",
    "pickle.dump(article_product, open(\"article_content_product.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the article product file\n",
    "article_product = pd.read_pickle(\"article_content_product.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique users \n",
    "users = np.unique(df2['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_articles(article_id):\n",
    "    '''\n",
    "    INPUT\n",
    "    article_id - an article_id \n",
    "    OUTPUT\n",
    "    similar_articles - an array of the most similar articles by description or top popular articles\n",
    "    '''\n",
    "    # find the row of each article_id\n",
    "    # Check if the article id exists.  if not return popular articles\n",
    "    if(len(np.where(df2['article_id'] == article_id)[0])==0):\n",
    "        print(\"The article id {} is not found.\\nRecommendations of top 10 popular articles.\".format(article_id))\n",
    "        print('='*90)\n",
    "        similar_articles = get_top_articles(10, df=df)\n",
    "    else:\n",
    "        article_idx = np.where(df2['article_id'] == article_id)[0][0]\n",
    "    \n",
    "        # find the most similar article_id indices - they need to be the same for all content\n",
    "        similar_idxs = np.where(article_product[article_idx] == np.max(article_product[article_idx]))[0]\n",
    "    \n",
    "        # pull the article titles based on the indices\n",
    "        similar_articles = np.array(df.iloc[similar_idxs, ]['title'])\n",
    "        \n",
    "    return similar_articles\n",
    "\n",
    "\n",
    "# Defined earlier\n",
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    # initialize an empty list\n",
    "    article_names = [df[df['article_id'] == idx]['title'].values[0] for idx in article_ids]\n",
    "        \n",
    "    \n",
    "    return article_names # Return the article names associated with list of article ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_content_recs():\n",
    "    '''\n",
    "    INPUT:\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "    '''\n",
    "    # Create dictionary to return with users and ratings\n",
    "    recs = defaultdict(set)\n",
    "    \n",
    "    # How many users for progress bar\n",
    "    n_users = len(users)\n",
    "\n",
    "    \n",
    "    # Create the progressbar\n",
    "\n",
    "    cnter = 0\n",
    "    bar = progressbar.ProgressBar(maxval=n_users+1, widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    bar.start()\n",
    "    \n",
    "    # For each user\n",
    "    for user in users:\n",
    "        \n",
    "        # Update the progress bar\n",
    "        cnter+=1 \n",
    "        bar.update(cnter)\n",
    "\n",
    "        # Pull only the articles the user has seen\n",
    "        content_temp = df2[df2['user_id'] == user]\n",
    "        article_temp = np.array(content_temp['article_id'])\n",
    "        article_names = np.array(get_article_names(article_temp))\n",
    "\n",
    "        # Look at each of the articles (highest ranked first), \n",
    "        # pull the movies the user hasn't seen that are most similar\n",
    "        # These will be the recommendations - continue until 10 recs \n",
    "        # or you have depleted the movie list for the user\n",
    "        for article in article_temp:\n",
    "            rec_article = find_similar_articles(article)\n",
    "            temp_recs = np.setdiff1d(rec_article, article_names)\n",
    "            recs[user].update(temp_recs)\n",
    "\n",
    "            # If there are more than \n",
    "            if len(recs[user]) > 9:\n",
    "                break\n",
    "\n",
    "    bar.finish()\n",
    "    \n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "recs = make_content_recs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 35 users without all 10 recommendations we would have liked to have.\n",
      "There were 4223 users with all 10 recommendations we would like them to have.\n",
      "There were 0 users with no recommendations at all!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "users_without_all_recs = []\n",
    "users_with_all_recs = []\n",
    "no_recs = []\n",
    "for user, article_recs in recs.items():\n",
    "    if len(article_recs) < 10:\n",
    "        users_without_all_recs.append(user)\n",
    "    if len(article_recs) > 9:\n",
    "        users_with_all_recs.append(user)\n",
    "    if len(article_recs) == 0:\n",
    "        no_recs.append(user)\n",
    "\n",
    "print(\"There were {} users without all 10 recommendations we would have liked to have.\".format(len(users_without_all_recs)))\n",
    "print(\"There were {} users with all 10 recommendations we would like them to have.\".format(len(users_with_all_recs)))\n",
    "print(\"There were {} users with no recommendations at all!\".format(len(no_recs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now that we have put together our content-based recommendation system, use the cell below to write a summary explaining how your content based recommender works.  Do you see any possible improvements that could be made to your function?  Is there anything novel about your content based recommender?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write an explanation of your content based recommendation system here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use your content-recommendation system to make recommendations for the below scenarios based on the comments.  Again no tests are provided here, because there isn't one right answer that could be used to find these content based recommendations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closer look at individual user characteristics\n",
    "user_items = df2[['user_id', 'article_id', 'description']]\n",
    "user_by_article = user_items.groupby(['user_id', 'article_id'])['description'].max().unstack()\n",
    "\n",
    "def articles_read(user_id):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id of an individual as int\n",
    "    OUTPUT:\n",
    "    movies - an array of movies the user has watched\n",
    "    '''\n",
    "    articles = user_by_article.loc[user_id][user_by_article.loc[user_id].isnull() == False].index.values\n",
    "\n",
    "    return articles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  14,   34,  111,  132,  142,  173,  189,  202,  302,  379,  390,\n",
       "        415,  427,  528,  542,  563,  583,  593,  606,  645,  692,  695,\n",
       "        723,  809,  878,  898,  943,  975,  981, 1017, 1042, 1047])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_read(8)\n",
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the article lists for users without all recommendations include:\n",
      "1\n",
      "deep learning with tensorflow course by big data university\n",
      "2\n",
      "using deep learning to reconstruct high-resolution audio\n",
      "3\n",
      "timeseries data analysis of iot events by using jupyter notebook\n",
      "4\n",
      "working interactively with rstudio and notebooks in dsx\n",
      "6\n",
      "how to solve 90% of nlp problems\n",
      "8\n",
      "got zip code data? prep it for analytics. â€“ ibm watson data lab â€“ medium\n",
      "9\n",
      "got zip code data? prep it for analytics. â€“ ibm watson data lab â€“ medium\n",
      "10\n",
      "10 must attend data science, ml and ai conferences in 2018\n",
      "11\n",
      "timeseries data analysis of iot events by using jupyter notebook\n",
      "12\n",
      "got zip code data? prep it for analytics. â€“ ibm watson data lab â€“ medium\n",
      "13\n",
      "got zip code data? prep it for analytics. â€“ ibm watson data lab â€“ medium\n"
     ]
    }
   ],
   "source": [
    "cnter = 0\n",
    "print(\"Some of the article lists for users without all recommendations include:\")\n",
    "for user_id in users_with_all_recs:\n",
    "    print(user_id)\n",
    "    print(get_article_names(articles_read(user_id))[0])\n",
    "    cnter+=1\n",
    "    if cnter > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recommendations for the user 300 are:\n",
      " \n",
      "data model with streaming analytics and python\n",
      "15 page tutorial for r\n",
      "ml optimization using cognitive assistant\n",
      "adolescent fertility rate (births per 1,000 women ages 15-19), worldwide\n",
      "use sql with data in hadoop python\n",
      "=========================================================================================\n",
      "The recommendations for the user 463 are:\n",
      " \n",
      "insights from new york car accident reports\n",
      "=========================================================================================\n",
      "The recommendations for the user 571 are:\n",
      " \n",
      "how to use version control (github) in rstudio within dsx?\n",
      "enjoy python 3.5 in jupyter notebooks\n",
      "an introduction to stock market data analysis with r (part 1)\n",
      "movie recommender system with spark machine learning\n",
      "=========================================================================================\n",
      "The recommendations for the user 685 are:\n",
      " \n",
      "machine learning and the science of choosing\n",
      "the pandas data analysis library\n",
      "super fast string matching in python\n",
      "ml optimization using cognitive assistant\n",
      "visualize car data with brunel\n",
      "=========================================================================================\n",
      "The recommendations for the user 754 are:\n",
      " \n",
      "real-time sentiment analysis of twitter hashtags with spark (+ pixiedust)\n",
      "fortune 100 companies\n",
      "working with ibm cloud object storage in python\n",
      "=========================================================================================\n",
      "The recommendations for the user 935 are:\n",
      " \n",
      "real-time sentiment analysis of twitter hashtags with spark (+ pixiedust)\n",
      "fortune 100 companies\n",
      "working with ibm cloud object storage in python\n",
      "=========================================================================================\n",
      "The recommendations for the user 983 are:\n",
      " \n",
      "apache spark lab, part 3: machine learning\n",
      "predicting gentrification using longitudinal census data\n",
      "deep learning with tensorflow course by big data university\n",
      "a dynamic duo â€“ inside machine learning â€“ medium\n",
      "finding optimal locations of new store using decision optimization\n",
      "=========================================================================================\n",
      "The recommendations for the user 1039 are:\n",
      " \n",
      "what is spark?\n",
      "develop a scala spark model on chicago building violations\n",
      "data structures related to machine learning algorithms\n",
      "neural networks for beginners: popular types and applications\n",
      "governance overview for ibm data catalog\n",
      "=========================================================================================\n",
      "The recommendations for the user 1138 are:\n",
      " \n",
      "probabilistic graphical models tutorialâ€Šâ€”â€Špart 1 â€“ stats and bots\n",
      "analyze energy consumption in buildings\n",
      "sector correlations shiny app\n",
      "intents & examples for ibm watson conversation\n",
      "housing (2015): united states demographic measures\n",
      "=========================================================================================\n",
      "The recommendations for the user 1505 are:\n",
      " \n",
      "fortune 100 companies\n",
      "hurricane how-to\n",
      "deep learning with tensorflow course by big data university\n",
      "times world university ranking analysis\n",
      "finding optimal locations of new store using decision optimization\n",
      "=========================================================================================\n",
      "The recommendations for the user 1654 are:\n",
      " \n",
      "access postgresql with python\n",
      "discover hidden facebook usage insights\n",
      "use ibm data science experience to detect time series anomalies\n",
      "520    using notebooks with pixiedust for fast, flexi...\n",
      "Name: title, dtype: object\n",
      "rstudio ide  cheat sheet\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for user in users_without_all_recs:\n",
    "    print(f\"The recommendations for the user {user} are:\\n \")\n",
    "    j = 1\n",
    "    for x in recs[user]:\n",
    "        print(x)\n",
    "        j+=1\n",
    "        if j>5:\n",
    "            break\n",
    "    print(\"=\"*89)\n",
    "    \n",
    "    i+=1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommenddatios for a brand new user byusing knowledge based recommendations are:\n",
      "==========================================================================================\n",
      "['use deep learning for image classification'\n",
      " 'insights from new york car accident reports'\n",
      " 'visualize car data with brunel'\n",
      " 'use xgboost, scikit-learn & ibm watson machine learning apis'\n",
      " 'predicting churn with the spss random tree algorithm'\n",
      " 'healthcare python streaming application demo'\n",
      " 'finding optimal locations of new store using decision optimization'\n",
      " 'apache spark lab, part 1: basic concepts'\n",
      " 'analyze energy consumption in buildings'\n",
      " 'gosales transactions for logistic regression model']\n",
      "==========================================================================================\n",
      "The article id 1427 is not found.\n",
      "Recommendations of top 10 popular articles.\n",
      "==========================================================================================\n",
      "['use deep learning for image classification'\n",
      " 'insights from new york car accident reports'\n",
      " 'visualize car data with brunel'\n",
      " 'use xgboost, scikit-learn & ibm watson machine learning apis'\n",
      " 'predicting churn with the spss random tree algorithm'\n",
      " 'healthcare python streaming application demo'\n",
      " 'finding optimal locations of new store using decision optimization'\n",
      " 'apache spark lab, part 1: basic concepts'\n",
      " 'analyze energy consumption in buildings'\n",
      " 'gosales transactions for logistic regression model']\n"
     ]
    }
   ],
   "source": [
    "# make recommendations for a brand new user \n",
    "#by using knowledge based recommendations using get_top_articles(n, df=df)\n",
    "print(f\"Recommenddatios for a brand new user by\\\n",
    "using knowledge based recommendations are:\")\n",
    "print(\"=\"*90)\n",
    "print(get_top_articles(10))\n",
    "print(\"=\"*90)\n",
    "\n",
    "# make a recommendations for a user who only has interacted with article id '1427.0'\n",
    "\n",
    "print(find_similar_articles(1427))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Matrix-Fact\">Part V: Matrix Factorization</a>\n",
    "\n",
    "In this part of the notebook, you will build use matrix factorization to make article recommendations to the users on the IBM Watson Studio platform.\n",
    "\n",
    "`1.` You should have already created a **user_item** matrix above in **question 1** of **Part III** above.  This first question here will just require that you run the cells to get things set up for the rest of **Part V** of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix here\n",
    "user_item_matrix = pd.read_pickle('user_item_matrix.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>1004.0</th>\n",
       "      <th>1006.0</th>\n",
       "      <th>1008.0</th>\n",
       "      <th>101.0</th>\n",
       "      <th>1014.0</th>\n",
       "      <th>1015.0</th>\n",
       "      <th>1016.0</th>\n",
       "      <th>...</th>\n",
       "      <th>977.0</th>\n",
       "      <th>98.0</th>\n",
       "      <th>981.0</th>\n",
       "      <th>984.0</th>\n",
       "      <th>985.0</th>\n",
       "      <th>986.0</th>\n",
       "      <th>990.0</th>\n",
       "      <th>993.0</th>\n",
       "      <th>996.0</th>\n",
       "      <th>997.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0  100.0  1000.0  1004.0  1006.0  1008.0  101.0  1014.0  1015.0  \\\n",
       "user_id                                                                         \n",
       "1           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "2           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "3           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "4           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "5           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "\n",
       "article_id  1016.0  ...    977.0  98.0  981.0  984.0  985.0  986.0  990.0  \\\n",
       "user_id             ...                                                     \n",
       "1              0.0  ...      0.0   0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "2              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3              0.0  ...      1.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "5              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "article_id  993.0  996.0  997.0  \n",
       "user_id                          \n",
       "1             0.0    0.0    0.0  \n",
       "2             0.0    0.0    0.0  \n",
       "3             0.0    0.0    0.0  \n",
       "4             0.0    0.0    0.0  \n",
       "5             0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick look at the matrix\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` In this situation, you can use Singular Value Decomposition from [numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html) on the user-item matrix.  Use the cell to perform SVD, and explain why this is different than in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing SVD on the User-Item Matrix here  using the built in to get the three matrices\n",
    "\n",
    "u, s, vt = np.linalg.svd(user_item_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5149, 5149), (714,), (714, 714))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape, s.shape, vt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the lesson, there are movie ratings but the IBM Watson platform has no article ratings. The ratings had different integer values (positive) making the user-item matrix to have varying values whereas the user-item matrix in of the user and articles have only ones and zeros.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now for the tricky part, how do we choose the number of latent features to use?  Running the below cell, you can see that as the number of latent features increases, we obtain a lower error rate on making predictions for the 1 and 0 values in the user-item matrix.  Run the cell below to get an idea of how the accuracy improves as we increase the number of latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8HXW9//HXO1vTfd8XUkoptIUu1LKKVRYBkaKAUlHBi6A/RdwVXLiK3ut61XsVVEQEZZNFsCCKiBQVFdrSjW50pUnXdEnbtE2zfX9/zCQM6Wlz0vbknCTv5+NxHpnlOzOfmXMyn5nvzHxHIQTMzMwA8rIdgJmZ5Q4nBTMza+SkYGZmjZwUzMyskZOCmZk1clIwM7NGTgpmByHpbknfzNKyJelXknZIeikbMVjH5KSQBZJmxf/snbIdS1siaa2kzZK6JoZ9WNKsLIaVKWcB5wHDQghTm46UdI2kf7R0ppKmSSo7GgHG8/uapHubKbNW0j5JlYnPkCNc7lFdD3udk0Irk1QCvBkIwCWtvOyC1lxehhQAn8x2EC0lKb+FkxwDrA0h7MlEPFnwzhBCt8RnQzaDaSf/CxnhpND6Pgj8G7gbuDo5QlJnSf8j6TVJOyX9Q1LneNxZkv4pqUJSqaRr4uGzJH04MY83HEFKCpI+LmkFsCIe9r/xPHZJmivpzYny+ZK+JGmVpN3x+OGSbpP0P03ifULSp5quoKSfSfp+k2G/l/SZuPuLktbH818u6ZwWbL/vAZ+T1CvFckvi9S1IDGvcPvG2eUHSD+PtuFrSGfHwUklbJF3dZLb9JD0Tx/q8pGMS8z4hHrc9Xo/3JMbdLemnkp6StAd4a4p4h0iaGU+/UtJ18fBrgTuB0+Oj6q+3YPsg6UOSlsYxr5b0kXh4V+CPwJDkEbukPEk3xd/5NkkPSerTZJteLWmdpK2SvhyPuwD4EvDeeF4LWhJnPI/TEr/rBZKmHcF6vKG6T03OJhSdsXxR0kJgj6SCeLpHJZVLWiPpxkT5qZLmxP8nmyX9oKXr1yaFEPxpxQ+wEvgYcApQAwxMjLsNmAUMBfKBM4BOwAhgNzADKAT6AhPjaWYBH07M4xrgH4n+ADwD9AE6x8PeH8+jAPgssAkojsd9HlgEjAEETIjLTgU2AHlxuX7A3mT8iWWeDZQCivt7A/uAIfF8S4Eh8bgSYFSa224tcC7wO+Cb8bAPA7MS8wpAQWKaxu0Tb5ta4EPx9v0msC7e7p2A8+Pt3C0uf3fcf3Y8/n8bti3QNV6PD8XbcTKwFRiXmHYncCbRwVdxivV5HrgdKAYmAuXAOam+xxTTHnQ88A5gVPz9vSX+nibH46YBZU3Kf4roQGVYvJ4/Bx5osk1/AXSOfw/7gRPj8V8D7k3ne0sxfCiwDbgo3kbnxf39D3M97m74XaQqE8cxHxger0seMBe4BSgCjgVWA2+Py/8L+EDc3Q04Ldv7j9b4ZD2AjvQhqieuAfrF/cuAT8fdeUQ7zgkpprsZeOwg85xF80nhbc3EtaNhucByYPpByi0Fzou7bwCeOkg5Ee1sz477rwP+GncfB2wh2rkXtnD7rY2nG0+0w+1Py5PCisS4k+LyycS8jdcT7t3Ag4lx3YC6eKfyXuDvTeL7OfCfiWl/fYh1GR7Pq3ti2LeAu1N9jymmP+T4JmUfBz4Zd0/jwJ3pUuJkFPcPjn+nBYltOiwx/iXgyrj7a6SXFCqBivjzeDz8i8BvmpR9Grj6MNfjbppPCv+R6D8VWJfif+1XcfffgK8T/792lI+rj1rX1cCfQwhb4/77eb0KqR/REeOqFNMNP8jwdJUmeyR9Nj4t3ympAugZL7+5Zd1DdJZB/Pc3qQqF6D/qQaIzG4D3AffF41YSHZl+Ddgi6UG18KJjCOEV4EngppZMF9uc6N4Xz6/psG6J/sZtF0KoBLYTnfEcA5waV3tUxNvxKmBQqmlTGAJsDyHsTgx7jejo+YhIulDSv+NqqQqiI/F+h5jkGOCxxHosJUpYAxNlNiW69/LGbZSOS0MIveLPpYnlXtFkG55FlJQOZz3SkfxOjiGqgkou/0u8vt7XAscDyyTNlnTxES67TfDFllai6NrAe4B8SQ3/YJ2AXpImEFXZVBGdLjetmy0lqr5JZQ/QJdE/KEWZxqZwFV0/+CJwDrA4hFAvaQfR0X3DskYBr6SYz73AK3G8JxIduR3MA8CfJX2b6IjsXY3BhHA/cL+kHkRH198BPnCIeaXyn8DLQPI6R8NF2S7Arrg71fZoieENHZK6EVXDbSDaTs+HEM47xLSHaoJ4A9BHUvdEYhgBrD+SYBXd0fYo0bWr34cQaiQ9zuvfb6qYSomOoF9IMb+SZhZ5JM0slxKdKVyXYrmHsx4t+l+Il78mhDA6VXAhhBXADEl5wLuBRyT1De3n4n9KPlNoPZcSHX2NJao/nki0Y/078MEQQj1wF/CD+OJXvqTT43+O+4BzJb0nvjjWV9LEeL7zgXdL6iLpOKKjm0PpTlSvXg4USLoF6JEYfyfwDUmjFTlZUl+AEEIZMJvoDOHREMK+gy0khDAvXsadwNMhhAoASWMkvS1eryqiI/O65jffAfNfCfwWuDExrJxop/r+ePv9B1GCOxIXKbrIXwR8A3gxhFBKdKZyvKQPSCqMP2+SdGKa8ZcC/wS+JalY0slE3919LYhN8bSNH6K68U5E275W0oVE10oabAb6SuqZGPYz4L8UX0SX1F/S9DRj2AyUxDvOlroXeKekt8ffV3F8cXjYYa7HfKLvq4+kQURnpIfyErArvvjcOY5hvKQ3AUh6v6T+8f9mRTxNi3+rbY2TQuu5mqiucl0IYVPDB/gJcJWiO2Y+R3TGMJuomuI7RBd21xGdOn82Hj6f6IIfwA+BaqJ/kntofqfyNNGdG68SVVdU8cZT6h8ADwF/Jjra/iXRRbkG9xDVxaesOmriAaJrAPcnhnUCvk10UXYTMIDolB1JV0lanMZ8G9xKdME36Tqii+XbgHFEO94jcT/RWcl2opsDrgKIj+7PB64kOurfRPR9teTZkxlEdfYbgMeIrkc804LpzyBKqk0/NxJ9hzuIqu5mNkwQQlhG9L2sjqtMhhBdQJ9JdGa3m+ii86lpxvBw/HebpJdbEHtDYpxO9P2XE/0OP0/0m999GOvxG6Kz7LVEv9/fNrP8OuCdRAdoa4h+k3cSVacCXAAsllRJtI2uDCFUtWQd26KGu0PM0iLpbKIjvJL4CMrM2hGfKVjaJBUSPTh2pxOCWfvkpGBpievKK4juDPlRlsMxswxx9ZGZmTXymYKZmTVqc88p9OvXL5SUlGQ7DDOzNmXu3LlbQwj9myvX5pJCSUkJc+bMyXYYZmZtiqTX0inn6iMzM2vkpGBmZo2cFMzMrJGTgpmZNXJSMDOzRhlLCpLuUvR6w1RNMBO3wPl/il5DuFDS5EzFYmZm6cnkmcLdRK0MHsyFwOj4cz3w0wzGYmZmacjYcwohhL8184KO6USvKwzAvyX1kjQ4hLAxUzGZWftUW1dPTV2guq6emrp6ausCtfUNfwN19VF/XX2gpu6N/bX1gboU5WrrG15RGb2ZJ/obNQvUMIwQDamrD9THrzdu6K4PgfqG4UTzadDY2cJmhs45cSAThvc68g12CNl8eG0ob2zHvywedkBSkHQ90dkEI0aMaJXgzOzw1NTVU1lVS+X+xKeqlr3VddTU1VNdW8/++G9Df0P3/tp69lXXUVVbR1VNHftq6qmqqUt86tlfW0dNXaCmtr4xCdS34SbcpObLNBjQo7hdJ4VUmyLlVxtCuAO4A2DKlClt+Os3y3319YHdVbVs31vN9j37qdhbw66qGnbtq2XXvkR31evdu6tqqNxfy+6qWvbXtrxVdQmK8vPoVJBH56J8igvzKS7Ip7gon+KCPPp0LYr6C/PoVJBPUUEehfl5FBaIovy4Oz+Pwnw1jsvPEwV5Ij9PB/QX5OVRkP/G/vw8UZCvxnJ5irob4hOK/zYEHQ3LE+RJ5OW93p2fF5XNk+JPw3q2IANkSTaTQhmJ998Cw4jeQGVmR9G+6jq27dnPjj01bN9bzY491WzfU82OvdHf7U36d+ytoe4Qh96dC/Pp0bmAHsWF9OhcSL9uRZT060r34gK6dyqga6cCunUqoFvc36046u9clE9Rfh5FBdGnU35+4069IN83QuaKbCaFmcANkh4kevXfTl9PMEtfbV095ZX72VBRxcad+9i0s6qxe+POKrbsqmL73mqqalIfuecJencpok/XInp3LeLYft2YUlJEny5Rf5+uhfTuUkTvLkX07FwY7fSLCykq8A68PctYUpD0ADAN6CepjOg9t4UAIYSfAU8RvXd4JbAX+FCmYjFrS0II7NpXy+bdVWzeVcXmXfvjv2/s37J7/wFH9J0L8xncq5ghPTtz7Ki+9OvWKd7xRzv4vt2KGhNBj+JC8vJyvzrDWlcm7z6a0cz4AHw8U8s3y3W1dfW8tn0vKzZXsnLLblZsqeTVzZWs2VqZ8ui+R3EBA3sUM6hnMcf278uQnp0bE8CgntHfHp0L2kS9teWuNtd0tllbU1cfeG3bHl7dvJvlmypZsWU3K7dUsrp8D9V1r+/8h/bqzOiB3Tj92L4M6VXMgB7FDOpRzMAenRjQvZjORflZXAvrKJwUzI6SEALrK/Y17vyjv7tZWV5JdXxHjgTDe3fh+IHdmDZmAKMHdGP0wG6M6t+Nrp3872jZ51+h2WHaWrmf+esqmFe6g3nrKlhYtpPK/bWN4wf3LOb4gd05a3Q/jh/YnTEDu3PcgG4+4rec5qRglobq2nqWbNzFvHVRAphXuoPS7fsAKMgTJw7uwaWThnDi4B6MGdid0QO707NzYZajNms5JwWzJhqqgeatq2B+aQXz1u3glQ27GquABvcsZtKIXnzwtBImjujF+CE9ffRv7YaTgnV4e6trWVi2MzoDWLeDeaUVlO/eD0CngjxOHtaTq08/hskjejNxRC8G9+yc5YjNMsdJwTqcEALLNu1m1vJyZi3fwtzXdlAb3+9f0rcLZx3Xj0kjejFpeG9OGNydQj9tax2Ik4J1CLuranhh5dY4EZSzaVcVACcM6s61bx7JqSP7MHF4b/p0LcpypGbZ5aRg7daq8kr+smQzzy3fwpy10dlA904FnDW6H9PG9Octxw9gUM/ibIdpllOcFKzdqK8PzC+r4M+LN/PMkk2sKt8DRGcDH37zsUwb059Tjunt6iCzQ3BSsDZtf20d/1y1jT8v3sxflm6mfPd+CvLEacf25YOnl3Du2IEM7eULw2bpclKwNieEwD9XbeOBl9bx3LIt7Kmuo2tRPtPGDOD8cQOZNmaAnxEwO0xOCtZm7NxbwyMvl3Hfv19j9dY99O5SyCUTh3L+uIGcMaovnQr8rIDZkXJSsJy3sKyC3/zrNZ5YuIGqmnomj+jFD987gQvHD6a40InA7GhyUrCctK+6jicWbODeF19jYdlOuhTl865Jw3j/aSMYN6RntsMza7ecFCynbNpZxT3/Wsv9L65j574aRg/oxq3Tx3HppKH0KPZ1ArNMc1KwnPDK+p388h9reGLBBupD4O3jBnH1GSWcOrKPXxpj1oqcFCxr6usDzy7bwp1/X82La7bTtSifD55ewofOLGF4ny7ZDs+sQ3JSsFa3t7qWR+eWcdcLa1mzdQ9Dehbz5YtO5L1Th7uKyCzLnBSs1dTVB347u5Tv/3k52/dUM2F4L348YxIXjh9EgZ8yNssJTgrWKl5cvY2vP7GEJRt3MXVkH77w9jGcckxvXy8wyzEZTQqSLgD+F8gH7gwhfLvJ+GOAu4D+wHbg/SGEskzGZK2rbMdevvXHZfxh4UaG9CzmJ++bxDtOGuxkYJajMpYUJOUDtwHnAWXAbEkzQwhLEsW+D/w6hHCPpLcB3wI+kKmYrPXsq67jp8+v4ufPr0KCT597PNeffazfUGaW4zJ5pjAVWBlCWA0g6UFgOpBMCmOBT8fdzwGPZzAeawUhBJ5YuJFvP7WUDTuruPjkwdx80YlulM6sjchkUhgKlCb6y4BTm5RZAFxGVMX0LqC7pL4hhG3JQpKuB64HGDFiRMYCtiOzurySm363iJfWbGfs4B786MpJTB3ZJ9thmVkLZDIppKo0Dk36Pwf8RNI1wN+A9UDtAROFcAdwB8CUKVOazsOyrLaunjv/sYYfPPMqxQV5/Pe7TuK9bxpOfp6vG5i1NZlMCmXA8ET/MGBDskAIYQPwbgBJ3YDLQgg7MxiTHWXLNu3iC48sZGHZTt4+biDfmD6eAT38NjOztiqTSWE2MFrSSKIzgCuB9yULSOoHbA8h1AM3E92JZG1AdW09tz23kttnraRHcSG3vW8yF500yHcVmbVxGUsKIYRaSTcATxPdknpXCGGxpFuBOSGEmcA04FuSAlH10cczFY8dPQvLKvjCIwtZtmk3l04cwi3vHOcX3pu1EwqhbVXRT5kyJcyZMyfbYXRIVTV1/PAvr/KLv61mQPdi/utd4znnxIHZDsvM0iBpbghhSnPl/ESzpWVBaQWffmg+q8v3MGPqcG6+6ES3U2TWDjkp2CHV1EXXDn7815UM7N6J+z58Kmce1y/bYZlZhjgp2EGtLq/k0w8tYEFpBe+eNJT/vGQcPTv77MCsPXNSsAOEELj3xXX81x+WUFyYz23vm8w7Th6c7bDMrBU4KdgbbN5VxRceWcjzr5Zz9vH9+d7lJzPQzx2YdRhOCtboqUUb+dJji6iqqeMb08fx/tOO8XMHZh2Mk4JRXVvPVx5fxENzypgwrCc/eO9ERvXvlu2wzCwLnBQ6uN1VNXz03rm8sHIbn3jbcdx4zmgK/RY0sw7LSaED27yrimt+NZsVm3fz/SsmcPkpw7IdkpllmZNCB7Vyy26uvms2O/ZW88tr3sRbju+f7ZDMLAc4KXRAc9Zu59p75lCYn8dvrz+dk4b1zHZIZpYjnBQ6mD+9solPPjiPIb06c8+HpjKib5dsh2RmOcRJoQP5zb/WcsvMxUwY1ou7rnmTWzY1swM4KXQAIQS+9/Rybp+1inNPHMCPZ0ymc1F+tsMysxzkpNDOhRD40mOLeOClUmZMHc43po+nwLecmtlBOCm0c3f+fQ0PvFTKR98yii9eMMZPKJvZIfmQsR17bvkWvvXHpVx00iC+8HYnBDNrnpNCO7WqvJIbH5jHmEE9+P4VE8jLc0Iws+Y5KbRDO/fVcN09cyjKz+MXHzyFLkWuJTSz9Hhv0c7U1Qc+8cA81m3fy/3Xncaw3n4OwczS56TQznz7j0v526vlfOvdJzF1ZJ9sh2NmbUxGq48kXSBpuaSVkm5KMX6EpOckzZO0UNJFmYynvXt0bhm/+Psarj79GGZMHZHtcMysDcpYUpCUD9wGXAiMBWZIGtuk2FeAh0IIk4ArgdszFU979/K6Hdz8u0WcMaovX7m46WY2M0tPJs8UpgIrQwirQwjVwIPA9CZlAtAj7u4JbMhgPO3Wpp1VfOQ3cxnUs5jb3jfZ70Mws8OWyb3HUKA00V8WD0v6GvB+SWXAU8AnUs1I0vWS5kiaU15enolY26yqmjo+8ps57N1fyy8+OIXebs/IzI5AJpNCqhvjQ5P+GcDdIYRhwEXAbyQdEFMI4Y4QwpQQwpT+/d3uf9KXH3uFhet38qMrJzFmUPdsh2NmbVwmk0IZMDzRP4wDq4euBR4CCCH8CygG+mUwpnblsXllPPpyGTe+bTTnjR2Y7XDMrB3IZFKYDYyWNFJSEdGF5JlNyqwDzgGQdCJRUnD9UBpe27aHrzz2ClNL+nDjOaOzHY6ZtRMZSwohhFrgBuBpYCnRXUaLJd0q6ZK42GeB6yQtAB4ArgkhNK1isiZq6uq58cH55OeJH145kXw3YWFmR0lGH14LITxFdAE5OeyWRPcS4MxMxtAe/eCZV1lQWsFPr5rM0F6dsx2OmbUjvnexjfnnyq387PlVzJg6nAtPGpztcMysnXFSaEO276nmU7+dz7H9uvJVP6BmZhngto/aiBACX3hkARV7a7j7Q1Pd8qmZZYTPFNqIX//rNf6ydAs3XXgCY4f0aH4CM7PD4KTQBizduIv/emopbx3Tnw+dWZLtcMysHXNSyHH7quu48YF59Cgu5HtXTPArNc0so1wxneO++YclrNhSya//Yyr9unXKdjhm1s75TCGHPb14E/e9uI7rzz6Ws493m09mlnlOCjlqx55qvvS7RYwb0oPPnT8m2+GYWQfh6qMc9Y0nl7BzXw33fvhUigqcu82sdXhvk4OeW76F381bz8emjeLEwb791Mxaj5NCjqncX8uXf7eI4wZ04+NvOy7b4ZhZB+PqoxzzvT8tY+OuKh756Ol0KsjPdjhm1sE0e6Yg6QZJvVsjmI5u9trt/Prfr3H16SWcckyfbIdjZh1QOtVHg4DZkh6SdIH89FRGVNXU8cVHFzKkZ2c+/3bfbWRm2dFsUgghfAUYDfwSuAZYIem/JY3KcGwdyo//uoLV5Xv41rtPomsn1+qZWXakdaE5fhvapvhTC/QGHpH03QzG1mEs3rCTnz+/mssmD/NDamaWVc0ekkq6Ebga2ArcCXw+hFAjKQ9YAXwhsyG2b7V19Xzx0YX06lLIVy8+MdvhmFkHl049RT/g3SGE15IDQwj1ki7OTFgdx53/WMMr63dx+1WT6dWlKNvhmFkHl0710VPA9oYeSd0lnQoQQliaqcA6gjVb9/DDZ17l7eMGcuH4QdkOx8wsraTwU6Ay0b8nHtas+G6l5ZJWSropxfgfSpoff16VVJFe2G1ffX3gpkcXUlSQx63Tx7tJbDPLCelUHym+0Aw0Vhulcy0iH7gNOA8oI7qtdWYIYUliXp9OlP8EMKklwbdlD84u5cU12/nOZScxsEdxtsMxMwPSO1NYLelGSYXx55PA6jSmmwqsDCGsDiFUAw8C0w9RfgbwQBrzbfP219bxv8++yptKevOeKcOzHY6ZWaN0ksJHgTOA9URH/KcC16cx3VCgNNFfFg87gKRjgJHAXw8y/npJcyTNKS8vT2PRue3RuevZvGs/nzzneFcbmVlOabYaKISwBbjyMOadam8XUgwjnv8jIYS6g8RwB3AHwJQpUw42jzahtq6enz2/ignDenLmcX2zHY6Z2Rukc22gGLgWGAc0Vn6HEP6jmUnLgGTdyDBgw0HKXgl8vLlY2oMnF25k3fa9fOUdp/gswcxyTjrVR78hav/o7cDzRDv33WlMNxsYLWmkpCKiHf/MpoUkjSF6Qvpf6QbdVtXXB26ftZLjB3bj3BMHZjscM7MDpJMUjgshfBXYE0K4B3gHcFJzE4UQaoEbgKeBpcBDIYTFkm6VdEmi6AzgweQdTu3VM0s38+rmSj427Tjy8nyWYGa5J51bUmvivxWSxhO1f1SSzsxDCE8RPfyWHHZLk/6vpTOvti6EwO3PrWREny5cfPLgbIdjZpZSOmcKd8TvU/gKUfXPEuA7GY2qHXph5TYWlO3ko28ZRUG+X3hnZrnpkGcKcaN3u0IIO4C/Ace2SlTt0E+eW8HAHp247JSUd+WameWEQx6yhhDqia4L2BGY+9p2/r16O9e9+Vi/YtPMclo69RjPSPqcpOGS+jR8Mh5ZO3L7c6vo3aWQGVNHZDsUM7NDSudCc8PzCMnnCAKuSkrLkg27eHbZFj5z3vF+o5qZ5bx0nmge2RqBtFe3z1pJt04FXH16SbZDMTNrVjpPNH8w1fAQwq+Pfjjty+rySv6waCMfOXsUPbsUZjscM7NmpVOf8aZEdzFwDvAy4KTQjJ89v4qi/DyuPcsnW2bWNqRTffSJZL+knkRNX9ghrK/Yx+9eXs9Vp46gf/dO2Q7HzCwth/MU1V5g9NEOpL35xd+iV05c/5ZRWY7EzCx96VxTeILXm7zOA8YCD2UyqLZua+V+HnhpHe+aNJShvTpnOxwzs7Slc03h+4nuWuC1EEJZhuJpF+5+YS3VdfV8dJrPEsysbUknKawDNoYQqgAkdZZUEkJYm9HI2qjaunoemlPKW8cMYFT/btkOx8ysRdK5pvAwUJ/or4uHWQp/X7GVLbv3854pw7IdiplZi6WTFApCCNUNPXF3UeZCatsenltKn65FvO0Ev0THzNqedJJCefKlOJKmA1szF1LbtX1PNc8s2cz0iUMoKnDz2GbW9qRzTeGjwH2SfhL3lwEpn3Lu6H4/fz01dYErThnefGEzsxyUzsNrq4DTJHUDFEJI5/3MHdLDc8oYP7QHY4f0yHYoZmaHpdk6Dkn/LalXCKEyhLBbUm9J32yN4NqSxRt2smTjLp8lmFmblk7F94UhhIqGnvgtbBdlLqS26eE5ZRTl5zF94pBsh2JmdtjSSQr5khob75HUGXBjPgn7a+v4/fz1nDduIL26+MYsM2u70kkK9wLPSrpW0rXAM8A96cxc0gWSlktaKemmg5R5j6QlkhZLuj/90HPHs0u3sGNvDVec4mcTzKxtS+dC83clLQTOBQT8CTimuekk5QO3AecR3bE0W9LMEMKSRJnRwM3AmSGEHZIGHN5qZNfDc0oZ1KOYN4/un+1QzMyOSLo3028ieqr5MqL3KSxNY5qpwMoQwur4gbcHgelNylwH3BZfpyCEsCXNeHLG5l1VPP9qOe+ePJT8PGU7HDOzI3LQMwVJxwNXAjOAbcBviW5JfWua8x4KlCb6y4BTm5Q5Pl7WC0A+8LUQwp9SxHI9cD3AiBEj0lx86/jdy+upD3C5q47MrB041JnCMqKzgneGEM4KIfyYqN2jdKU6bA5N+guI3s0wjSj53Cmp1wEThXBHCGFKCGFK//65U0UTQuDhuaW8qaQ3x7rxOzNrBw6VFC4jqjZ6TtIvJJ1D6h39wZQByZv2hwEbUpT5fQihJoSwBlhOG3qBz8vrdrC6fI+fTTCzduOgSSGE8FgI4b3ACcAs4NPAQEk/lXR+GvOeDYyWNFJSEVFV1MwmZR4H3gogqR9RddLqFq9Fljw8p4zOhflcdPLgbIdiZnZUNHuhOYSwJ4RwXwjhYqKj/flAyttLm0xXC9wAPE10YfqhEMJiSbcmGth7GtgmaQnwHPD5EMK2w1yXVrW3upYnF27kopMG061TOk1ImZnlvhbtzUII24EyJZo7AAARQUlEQVSfx590yj8FPNVk2C2J7gB8Jv60KX96ZROV+2u5wu9NMLN2xO07H6aH55RxTN8unDqyT7ZDMTM7apwUDsO6bXv51+ptXD55GJKfTTCz9sNJ4TA88nIZElzmZxPMrJ1xUmih+vrAo3PLOOu4fgzp1Tnb4ZiZHVVOCi30r9XbWF+xjyum+NkEM2t/nBRa6NGXy+heXMD5YwdmOxQzs6POSaEFqmrq+PPizVw4fhDFhfnZDsfM7KhzUmiB55ZtoXJ/LZdMGJrtUMzMMsJJoQVmLthAv26dOH1U32yHYmaWEU4KadpdVcOzy7bwjpMG+b0JZtZuOSmk6Zklm6mureeSiUOyHYqZWcY4KaRp5oINDO3Vmckjemc7FDOzjHFSSMP2PdX8Y8VW3jlhiJu1MLN2zUkhDU8t2khtfeCdE/zeBDNr35wU0vDEgg2M6t+VsYN7ZDsUM7OMclJoxqadVby0djuXTBjqqiMza/ecFJrx5MINhIDvOjKzDsFJoRkzF2zgpKE9Gdmva7ZDMTPLOCeFQ1izdQ8Ly3b6ArOZdRhOCofw5IINAFx8squOzKxjcFI4iBACMxdsYGpJH79Mx8w6jIwmBUkXSFouaaWkm1KMv0ZSuaT58efDmYynJZZt2s2KLZW80xeYzawDKcjUjCXlA7cB5wFlwGxJM0MIS5oU/W0I4YZMxXG4Zi7YQH6euGj8oGyHYmbWajJ5pjAVWBlCWB1CqAYeBKZncHlHTQiBJxZs4Mzj+tG3W6dsh2Nm1moymRSGAqWJ/rJ4WFOXSVoo6RFJKV98LOl6SXMkzSkvL89ErG8wr7SCsh37uGSCq47MrGPJZFJI9fhvaNL/BFASQjgZ+AtwT6oZhRDuCCFMCSFM6d+//1EO80Az52+gqCCP88f5Pcxm1rFkMimUAckj/2HAhmSBEMK2EML+uPcXwCkZjCctdfWBPyzayFvH9KdHcWG2wzEza1WZTAqzgdGSRkoqAq4EZiYLSEo+FXYJsDSD8aTl36u3Ub57v9/DbGYdUsbuPgoh1Eq6AXgayAfuCiEslnQrMCeEMBO4UdIlQC2wHbgmU/Gk64kFG+halM85Jw7IdihmZq0uY0kBIITwFPBUk2G3JLpvBm7OZAwtUV1bzx9f2cT54wZRXJif7XDMzFqdn2hO+Nur5ezcV+O7jsysw3JSSJj16ha6dSrgzOP6ZTsUM7OscFJImF9awcnDelJU4M1iZh2T936xqpo6lm3czcThvbIdiplZ1jgpxF5Zv5Pa+uCkYGYdmpNCbH5pBQATRzgpmFnH5aQQm19awdBenRnQvTjboZiZZY2TQmx+aYWrjsysw3NSALZW7qdsxz4nBTPr8JwUgPnrfD3BzAycFICo6ig/T4wf0jPboZiZZZWTAlFSOGFQdzoXub0jM+vYOnxSqK8PLPBFZjMzwEmB1Vsr2b2/1knBzAwnBebFF5kn+SKzmZmTwvzSCroXF3Bsv27ZDsXMLOucFEormDCsF3l5ynYoZmZZ16GTwr7qOpZtcsuoZmYNOnRSeGXDTurcMqqZWaMOnRQanmSe4KRgZgZkOClIukDSckkrJd10iHKXSwqSpmQynqYaWkbt371Tay7WzCxnZSwpSMoHbgMuBMYCMySNTVGuO3Aj8GKmYjmY+aUVbu/IzCwhk2cKU4GVIYTVIYRq4EFgeopy3wC+C1RlMJYDbNldxfqKfUxy1ZGZWaNMJoWhQGmivywe1kjSJGB4COHJDMaRUmPLqE4KZmaNMpkUUt34HxpHSnnAD4HPNjsj6XpJcyTNKS8vPyrBzS+toCBPjB/qllHNzBpkMimUAcMT/cOADYn+7sB4YJaktcBpwMxUF5tDCHeEEKaEEKb079//qAQ3v7SCEwZ3p7jQLaOamTXIZFKYDYyWNFJSEXAlMLNhZAhhZwihXwihJIRQAvwbuCSEMCeDMQFQVx9YWLbTVUdmZk1kLCmEEGqBG4CngaXAQyGExZJulXRJppabjlXllVTur2Xi8N7ZDMPMLOcUZHLmIYSngKeaDLvlIGWnZTKWJF9kNjNLrUM+0TyvsWXUrtkOxcwsp3TIpDA/ftOaW0Y1M3ujDpcU9lbXsnzTLlcdmZml0OGSwqKyndQHX08wM0ulwyWF+aW+yGxmdjAdMikM79OZvt3cMqqZWVMdMin4+QQzs9Q6VFLYvKuKjTurXHVkZnYQHSopzPNDa2Zmh9ShksL80goK88W4IT2yHYqZWU7qYElhBycO7uGWUc3MDqLDJIW6+sAit4xqZnZIHSYprNxSyZ7qOicFM7ND6DBJYX7pDsAXmc3MDqXDJIXeXYo4b+xARrplVDOzg8ro+xRyyfnjBnH+uEHZDsPMLKd1mDMFMzNrnpOCmZk1clIwM7NGTgpmZtbIScHMzBplNClIukDSckkrJd2UYvxHJS2SNF/SPySNzWQ8ZmZ2aBlLCpLygduAC4GxwIwUO/37QwgnhRAmAt8FfpCpeMzMrHmZPFOYCqwMIawOIVQDDwLTkwVCCLsSvV2BkMF4zMysGZl8eG0oUJroLwNObVpI0seBzwBFwNtSzUjS9cD1cW+lpOVpxtAP2JpuwDmircXc1uIFx9xa2lrMbS1eaFnMx6RTKJNJQSmGHXAmEEK4DbhN0vuArwBXpyhzB3BHiwOQ5oQQprR0umxqazG3tXjBMbeWthZzW4sXMhNzJquPyoDhif5hwIZDlH8QuDSD8ZiZWTMymRRmA6MljZRUBFwJzEwWkDQ60fsOYEUG4zEzs2ZkrPoohFAr6QbgaSAfuCuEsFjSrcCcEMJM4AZJ5wI1wA5SVB0doRZXOeWAthZzW4sXHHNraWsxt7V4IQMxKwTf8GNmZhE/0WxmZo2cFMzMrFG7TArNNa+RLZLukrRF0iuJYX0kPSNpRfy3dzxckv4vXoeFkiZnKebhkp6TtFTSYkmfzOW4JRVLeknSgjjer8fDR0p6MY73t/HND0jqFPevjMeXtGa8TWLPlzRP0pNtIWZJaxPN1MyJh+Xk7yIRcy9Jj0haFv+mT8/lmCWNibdvw2eXpE9lNOYQQrv6EF3UXgUcS/RA3AJgbLbjimM7G5gMvJIY9l3gprj7JuA7cfdFwB+Jnvc4DXgxSzEPBibH3d2BV4maLcnJuOPldou7C4EX4zgeAq6Mh/8M+H9x98eAn8XdVwK/zeLv4zPA/cCTcX9OxwysBfo1GZaTv4tEfPcAH467i4BeuR5zIvZ8YBPRQ2gZizlrK5jBDXc68HSi/2bg5mzHlYinpElSWA4MjrsHA8vj7p8DM1KVy3L8vwfOawtxA12Al4mepN8KFDT9jRDdHXd63F0Ql1MWYh0GPEv0VP+T8T91rsecKink7O8C6AGsabqtcjnmJnGeD7yQ6ZjbY/VRquY1hmYplnQMDCFsBIj/DoiH59x6xNUUk4iOvnM27rgaZj6wBXiG6MyxIoRQmyKmxnjj8TuBvq0Zb+xHwBeA+ri/L7kfcwD+LGmuoqZoIId/F0S1B+XAr+JqujsldSW3Y066Engg7s5YzO0xKaTVvEYbkFPrIakb8CjwqfDGhgwPKJpiWKvGHUKoC1HLu8OIGmY88RAxZT1eSRcDW0IIc5ODUxTNmZhjZ4YQJhO1hPxxSWcfomwuxFxAVH370xDCJGAPUdXLweRCzADE15MuAR5urmiKYS2KuT0mhZY2r5FtmyUNBoj/bomH58x6SCokSgj3hRB+Fw/O+bhDCBXALKK61V6SGh7WTMbUGG88viewvXUj5UzgEklriZp7eRvRmUMux0wIYUP8dwvwGFECzuXfRRlQFkJ4Me5/hChJ5HLMDS4EXg4hbI77MxZze0wKzTavkWNm8vqT3FcT1dk3DP9gfDfBacDOhtPF1iRJwC+BpSGE5PsucjJuSf0l9Yq7OwPnAkuB54DLDxJvw3pcDvw1xJWxrSWEcHMIYVgIoYTo9/rXEMJV5HDMkrpK6t7QTVTf/Qo5+rsACCFsAkoljYkHnQMsyeWYE2bwetURZDLmbF00yfAFmYuI7pJZBXw52/Ek4noA2EjUrEcZcC1RXfCzRO0+PQv0icuK6CVFq4BFwJQsxXwW0ennQmB+/LkoV+MGTgbmxfG+AtwSDz8WeAlYSXQK3ikeXhz3r4zHH5vl38g0Xr/7KGdjjmNbEH8WN/yf5ervIhH3RGBO/Pt4HOjdBmLuAmwDeiaGZSxmN3NhZmaN2mP1kZmZHSYnBTMza+SkYGZmjZwUzMyskZOCmZk1clKwIyYpSPqfRP/nJH3tKM37bkmXN1/yiJdzRdxq5nNNhpco0aptGvO5VNLYI4ijRNL7DjFuX5NWM4uO5jLMnBTsaNgPvFtSv2wHkiQpvwXFrwU+FkJ46xEu9lKiVmQPVwlwqB32qhDCxMSnOgPLSKmF29PaKCcFOxpqid4V++mmI5oe6UuqjP9Ok/S8pIckvSrp25KuUvQuhEWSRiVmc66kv8flLo6nz5f0PUmz43bjP5KY73OS7id6eKdpPDPi+b8i6TvxsFuIHtL7maTvpbPCkq6Ll71A0qOSukg6g6h9mu/FR/Gj4s+f4kbj/i7phMR2+T9J/5S0OrGNvg28OZ7+gO15kFi6KnpXx2xFDb1Nj4eXxMt8Of6ckWoZkq6R9JPE/J6UNC3urpR0q6QXgdMlnRJ/b3MlPa3Xm1q4UdKS+Lt4MJ24LUdl4wk9f9rXB6gkapZ4LVE7PJ8DvhaPuxu4PFk2/jsNqCBq9rcTsB74ejzuk8CPEtP/iegAZjTRk+DFwPXAV+IynYieUh0Zz3cPMDJFnEOAdUB/osbR/gpcGo+bRYqnP2nS1HlieN9E9zeBTxxkfZ8FRsfdpxI1SdFQ7uF4vcYCKxPb5cmDbOcSYB+vP1l+Wzz8v4H3x929iJ7m70r0JGxxPHw0MCfVMoBrgJ8k+p8EpsXdAXhP3F0I/BPoH/e/F7gr7t7A609c98r2b9Kfw/80NLZldkRCCLsk/Rq4kWjHlY7ZIW6XRdIq4M/x8EVAshrnoRBCPbBC0mrgBKK2dk5OHGH3JNrxVQMvhRDWpFjem4BZIYTyeJn3Eb346PE0400aL+mbRDvhbkTvOHgDRS3LngE8LDU2XtkpUeTxeL2WSBqY5nJXhagF2KTziRrU+1zcXwyMINpR/0TSRKAOOD7NZSTVETWGCDAGGA88E69PPlGzLRA1G3GfpMc5vO1pOcJJwY6mHxG91OZXiWG1xNWUivYkyQuj+xPd9Yn+et7422zaFksgauPlEyGEN+yM42qPPQeJL1WzwofrbqKzjAWSriE6+m4qj+idCE134g2S638ksQm4LISw/A0Do4v9m4EJcSxVB5m+8TuKFSe6q0IIdYnlLA4hnJ5iHu8gSrCXAF+VNC68/i4Ia0N8TcGOmhDCdqJXSF6bGLwWOCXunk5UBdFSV0jKi68zHEv0Nqmngf+nqFlvJB2vqLXOQ3kReIukfvFF0xnA84cRD0SvJt0YL/+qxPDd8ThC9N6JNZKuiGOUpAnNzLdx+hZ4GvhEnHSRNCke3hPYGJ+NfIDoyD7VMtYCE+NtPJyoCexUlgP9JZ0eL6dQ0jhJecDwEMJzRC8Kajh7sjbIScGOtv8Bknch/YJoR/wSUZ36wY7iD2U50c77j8BHQwhVwJ1EzR6/rOiW0Z/TzJlvXFV1M1GT1AuI2qf//aGmiY2RVJb4XAF8lSjJPAMsS5R9EPh8fMF3FFHCuFZSQ2ui05tZ1kKgNr6AndaFZuAbRMl2YbwtvhEPvx24WtK/iaqOGrZ902W8QPSaykXA94nO9g4QojudLge+E6/PfKLqsXzgXkmLiFqo/WGI3mVhbZBbSTUzs0Y+UzAzs0ZOCmZm1shJwczMGjkpmJlZIycFMzNr5KRgZmaNnBTMzKzR/wc1kNaIzW6PxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a05dccfd0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "    \n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` From the above, we can't really be sure how many features to use, because simply having a better way to predict the 1's and 0's of the matrix doesn't exactly give us an indication of if we are able to make good recommendations.  Instead, we might split our dataset into a training and test set of data, as shown in the cell below.  \n",
    "\n",
    "Use the code from question 3 to understand the impact on accuracy of the training and test sets of data with different numbers of latent features. Using the split below: \n",
    "\n",
    "* How many users can we make predictions for in the test set?  \n",
    "* How many users are we not able to make predictions for because of the cold start problem?\n",
    "* How many articles can we make predictions for in the test set?  \n",
    "* How many articles are we not able to make predictions for because of the cold start problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id\n",
       "0        1430  using pixiedust for fast, flexible, and easier...        1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.head(40000)\n",
    "df_test = df.tail(5993)\n",
    "\n",
    "def create_test_and_train_user_item(df_train, df_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df_train - training dataframe\n",
    "    df_test - test dataframe\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item_train - a user-item matrix of the training dataframe \n",
    "                      (unique users for each row and unique articles for each column)\n",
    "    user_item_test - a user-item matrix of the testing dataframe \n",
    "                    (unique users for each row and unique articles for each column)\n",
    "    test_idx - all of the test user ids\n",
    "    test_arts - all of the test article ids\n",
    "    \n",
    "    '''\n",
    "    user_item_train = create_user_item_matrix(df_train)\n",
    "    user_item_test = create_user_item_matrix(df_test)\n",
    "    test_idx =  user_item_test.iloc[: , 0].index\n",
    "    test_arts = user_item_test.iloc[0, :].index\n",
    "    test_idx = list(test_idx)\n",
    "    test_arts = list(test_arts)\n",
    "    return user_item_train, user_item_test, test_idx, test_arts\n",
    "\n",
    "user_item_train, user_item_test, test_idx, test_arts = create_test_and_train_user_item(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682\n",
      "(682, 574)\n",
      "574\n"
     ]
    }
   ],
   "source": [
    "print(len(test_idx))\n",
    "#user_item_train\n",
    "print(user_item_test.shape)\n",
    "print(len(test_arts))\n",
    "#test_arts\n",
    "#test_idx['user_id'].nunique() #shape\n",
    "#np.unique(test_arts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome job!  That's right!  All of the test movies are in the training data, but there are only 20 test users that were also in the training set.  All of the other users that are in the test set we have no data on.  Therefore, we cannot make predictions for these users using SVD.\n"
     ]
    }
   ],
   "source": [
    "# Replace the values in the dictionary below\n",
    "a = 662 \n",
    "b = 574 \n",
    "c = 20 \n",
    "d = 0 \n",
    "\n",
    "\n",
    "sol_4_dict = {\n",
    "    'How many users can we make predictions for in the test set?': c, \n",
    "    'How many users in the test set are we not able to make predictions for because of the cold start problem?': a,\n",
    "    'How many movies can we make predictions for in the test set?': b,\n",
    "    'How many movies in the test set are we not able to make predictions for because of the cold start problem?': d\n",
    "}\n",
    "\n",
    "t.sol_4_test(sol_4_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Now use the **user_item_train** dataset from above to find U, S, and V transpose using SVD. Then find the subset of rows in the **user_item_test** dataset that you can predict using this matrix decomposition with different numbers of latent features to see how many features makes sense to keep based on the accuracy on the test data. This will require combining what was done in questions `2` - `4`.\n",
    "\n",
    "Use the cells below to explore how well SVD works towards making predictions for recommendations on the test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4487, 4487), (714,), (714, 714))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit SVD on the user_item_train matrix\n",
    "u_train, s_train, vt_train =  np.linalg.svd(user_item_train) \n",
    "u_train.shape, s_train.shape, vt_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2917 3024 3093 3193 3527 3532 3684 3740 3777 3801 3968 3989 3990 3998 4002\n",
      " 4204 4231 4274 4293 4487]\n"
     ]
    }
   ],
   "source": [
    "# Finding the users we can make predictions for in the test set.\n",
    "predictable_users = np.sort(np.array(list(set(user_item_train.index).intersection(set(user_item_test.index)))))\n",
    "print(predictable_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6a060729e8>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8FOX9wPHPd5NAQggJJNyH4ZJbEeKBB16o4AVqvapWqEq1ov60tmBbLf7sgfawWjygatHWo7aIUCsgonj+BCJCwiEQDiGcOUggkECSfX5/zJMwCRvYHJvZZL/vl+POPPPMzHcmy353npl9RowxKKWUUsHweR2AUkqppkOThlJKqaBp0lBKKRU0TRpKKaWCpklDKaVU0DRpKKWUCpomDaXqSERmicivPdq2iMjfRGSfiCzzIgYVmTRphCERWWI/DFp6HUtTIiJbRWSPiMS7yu4UkSUehhUq5wKXAN2MMWdUnyki40Xk89quVEQuEJHshgjQrm+qiPzjBHW2ikixiBS5hi713G6D7oc6SpNGmBGRVOA8wABXN/K2oxtzeyESDTzgdRC1JSJRtVzkJGCrMeZgKOLxwFXGmNauYaeXwTSTfwshoUkj/PwA+AqYBdzuniEicSLyRxH5TkQKReRzEYmz884VkS9FpEBEtovIeFu+RETudK2jyjdQETEicq+IbAQ22rJn7Dr2i8jXInKeq36UiPxcRDaJyAE7v7uIPCcif6wW739E5H+q76CIvCgif6hWNldEHrLjk0Vkh13/ehG5uBbH7/fAwyKSFGC7qXZ/o11llcfHHpsvRORpexw3i8jZtny7iOwVkdurrTZFRBbZWD8RkZNc6+5v5+Xb/bjBNW+WiLwgIu+LyEHgwgDxdhGReXb5LBG5y5bfAbwEjLDfyh+vxfFBRCaIyDob82YR+ZEtjwfmA13c3/hFxCciU+zfPE9E3haRdtWO6e0isk1EckXkF3beaODnwI12XatqE6ddx1mu9/UqEbmgHvtRpTlRqp2NiHPGM1lEMoCDIhJtl5stIjkiskVE7nfVP0NE0u2/kz0i8qfa7l+TZIzRIYwGIAv4MTAcKAU6uuY9BywBugJRwNlAS6AHcAC4GYgBkoGhdpklwJ2udYwHPndNG2AR0A6Is2W32nVEAz8BdgOxdt5PgUygHyDAqbbuGcBOwGfrpQCH3PG7tjkS2A6InW4LFANd7Hq3A13svFSgd5DHbiswCngH+LUtuxNY4lqXAaJdy1QeH3tsyoAJ9vj+Gthmj3tL4FJ7nFvb+rPs9Eg7/5mKYwvE2/2YYI/jMCAXGORathA4B+fLW2yA/fkEeB6IBYYCOcDFgf6OAZatcT5wBdDb/v3Ot3+nYXbeBUB2tfr/g/NFppvdzxnAm9WO6V+BOPt+OAwMsPOnAv8I5u8WoLwrkAdcbo/RJXa6fR33Y1bF+yJQHRvHSqC73Rcf8DXwGNAC6AVsBi6z9f8PuM2OtwbO8vrzozEGzwPQwfXHcNqpS4EUO/0t8KAd9+F8sJ4aYLlHgDk1rHMJJ04aF50grn0V2wXWA2NrqLcOuMSOTwLer6Ge4HwYj7TTdwEf2fE+wF6cD/+YWh6/rXa5wTgfyO2pfdLY6Jo3xNZ3J+48jibkWcBbrnmtgXL7oXMj8Fm1+GYAv3It+9px9qW7XVeCq+x3wKxAf8cAyx93frW67wIP2PELOPbDdh02WdnpzvZ9Gu06pt1c85cBN9nxqQSXNIqAAju8a8snA3+vVnchcHsd92MWJ04aP3RNnwlsC/Bv7W92/FPgcey/10gZtHkqvNwOfGCMybXTb3C0iSoF5xvnpgDLda+hPFjb3RMi8hN72l8oIgVAot3+ibb1Ks5ZCvb174EqGedf3Fs4Z0YA3wdet/OycL7ZTgX2ishbUsuLosaY1cB7wJTaLGftcY0X2/VVL2vtmq48dsaYIiAf54zpJOBM26xSYI/jLUCnQMsG0AXIN8YccJV9h/Ptu15EZIyIfGWbvQpwvsmnHGeRk4A5rv1Yh5PQOrrq7HaNH6LqMQrGOGNMkh3GubZ7fbVjeC5O0qrLfgTD/Tc5CaeJy739n3N0v+8ATga+FZHlInJlPbfdJOjFnjAhzrWJG4AoEan4B9gSSBKRU3GahEpwTsertw1vx2keCuQg0Mo13SlAncqujsW5fjEZuBhYY4zxi8g+nLODim31BlYHWM8/gNU23gE43/xq8ibwgYhMw/lGd01lMMa8AbwhIm1wvp0/Cdx2nHUF8itgBeC+zlJx0bgVsN+OBzoetdG9YkREWuM08+3EOU6fGGMuOc6yx+tieifQTkQSXImjB7CjPsGKc0febJxrZ3ONMaUi8i5H/76BYtqO8w38iwDrSz3BJuvTjfZ2nDONuwJsty77Uat/C3b7W4wxfQMFZ4zZCNwsIj7gWuDfIpJsms/NCQHpmUb4GIfz7W0gTvv1UJwP3s+AHxhj/MArwJ/sxbkoERlh//G8DowSkRvsxbtkERlq17sSuFZEWolIH5xvR8eTgNOunwNEi8hjQBvX/JeAJ0SkrzhOEZFkAGNMNrAc5wxjtjGmuKaNGGO+sdt4CVhojCkAEJF+InKR3a8SnG/25Sc+fMesPwv4J3C/qywH50P3Vnv8foiTAOvjcnFuQmgBPAEsNcZsxznTOVlEbhORGDucLiIDgox/O/Al8DsRiRWRU3D+dq/XIjaxy1YOOG3zLXGOfZmIjMG5VlNhD5AsIomusheB34i9yC8i7UVkbJAx7AFS7Qdrbf0DuEpELrN/r1h78bpbHfdjJc7fq52IdMI5oz2eZcB+e3E8zsYwWEROBxCRW0Wkvf23WWCXqfV7tanRpBE+bsdpK91mjNldMQDTgVvEuePnYZwzjuU4zSBP4lx43oZzav4TW74S54IkwNPAEZx/RK9y4g+dhTh3nmzAaQ4poeop+5+At4EPcL6tv4xz0bDCqzjXAgI2TVXzJs41iDdcZS2BaTgXjXcDHXCaBBCRW0RkTRDrrfC/OBek3e7CuZifBwzC+WCujzdwzmrycW5euAXAnh1cCtyEc9awG+fvVZvf3tyMc81gJzAH53rIolosfzZO0q0+3I/zN9yH0zQ4r2IBY8y3OH+XzbZJpgvOBf55OGeGB3Auip8ZZAz/sq95IrKiFrFXJM6xOH//HJz34U9x3vMH6rAff8c5S9+K8/795wm2Xw5chfMFbgvOe/IlnOZagNHAGhEpwjlGNxljSmqzj01Rxd0rSjUIERmJ8w0x1X4DU0o1I3qmoRqMiMTg/LDuJU0YSjVPmjRUg7Bt9QU4d7b82eNwlFIhos1TSimlgqZnGkoppYLW7H6nkZKSYlJTU70OQymlmpSvv/461xjT/kT1ml3SSE1NJT093eswlFKqSRGR74Kpp81TSimlgqZJQymlVNA0aSillAqaJg2llFJB06ShlFIqaJ4mDRF5RZxHaAbqZhvbi+qz4jzqMkNEhjV2jEoppY7y+kxjFk5PkTUZA/S1w0TghUaISSmlVA08/Z2GMebTEzzEZSzOIzEN8JWIJIlIZ2PMrkYJMEh+v6HcGPzG4PdTOW5c436/wW/stN9gDE65ccqNfa0oq5hf+UrFo3mprG9w5uH8V1nfXddgX93lONPgrn+0rjMH3F3MHDPfHH1aTcU6Kxfk2HVVLFPTvIqCY+rWUF5l2WqxUqXcXd8cUx5oqeqrMgFq1aX3nWC67AlUpXpRQ/X8E2i/goknVJpkh0Zh1g1Tp8Q4vn9mj5BuI9x/3NeVqs9yyLZlVZKGiEzEOROhR4+6HbCCQ0e45aWllPsNpeV+yv2GMr+pfC0r91dOl/udD/ZymwiUUpFL5MR1GsvQ7kkRnzQC/TmO+Zg2xswEZgKkpaXV6WM8qrSIJ0qm4ZcojC8af1Q0JiYa7LTxRYMvGiPR4IsC8dl5dtwXBRIFvijE58NINMYXY6ePLk9UNIgzLlHuZaKcMp/PebXrlor6Uc76nOkYZz2+KPDFID4fPhFEnAMmAiJix+VoGVL5BndPVxnH/Y/gaBnV1mXnVvkHc3TdUvnHc9etUqfyfzXMq7aeqvPdGz12+9WKK9dzbHmA9QVYV02q1wm0njqtN+BycsI6dRHcfobRp6LyXLgnjWxcz2AGuuE8xazBJcTAsIQCKC8Ffxn4S8Ff7poud8rKS8GUQ7g9LsImMefV50psYsvl6LyKAXHV8R1bB/d0gDo1zQ9Y7l7GlbmoNh7o1b1c5TiB6x+zLoIYdy9H4Pm1/uAMsK4q0429nsjkN4ZS/JQaP0dMeeVrGYZy46ccQ5l9LTd+W24ox0+5MRgMfmyTqmudxlVW8eoPUL+irh8/fjvtxw6V41XX727urdo4e2Id4jtz3SV/rO9hO65wTxrzgEki8hbO4yULQ3Y9o1U7uOeL4Osb4yQOf7mTRKq8+m2iKTuacCqTjysBBVq2yniZs64aE1np0e1VDFWmzdF1YVxl/gDj5bZ9NtB8V1nA+a7x8optHW8Zc7SOczCPLatczh0TVfcj0HLusoq/U8BxglvOXVab98bRjRw7Xdf1NDMGOCJQIj6KRSj2CYfEx0HX60Gfj0PivFaUH/YJJXJ0OGyXPVxZ5qNMoFSEsghLrqfsW8d1Id6Gp0lDRN4ELgBSRCQb51nLMQDGmBeB93GefZ0FHAImeBNpABXf4H1RXkeiIo3HF1/L/eUcOHKAwiOFFBwuoPDwfopKD1BUepCDR4o4UFrEwdKDFFW8HnHmlZSVUFJeTHFZiR0vwV+LM/ZW0a1oFdOK2KhYYqNjK1/bRLWkY3QsLe10y6iWtPDFEBPVghhfjDNExdDC14IYXzQxUTFESzTRvhiifVFESRRRviiiJNo1HU2U+PDhnC0755uCT6pOiwg+iUIAn/jwia+yXsV8ESFKopz5+BBxmpMr6lfWrTyD5ug02Gbh8El+Xt89dfMJ5hvg3kYKR6mmoQG/PZeUlVBwuKDKUFhSWHX6cCGFh22COFLI/sP7j3vnlU98xMfEkxCTQHyLeFrHtKZtbFviouOIi447+qEfHXvMdHx0PPExztAqplXleFx0nPOBrTwX7s1TSqlaMMZwoPQAucW55BXnkVeS57wW55Ffkk9eSR75xfa1JJ/isuIa1xUfE09SyyQSWyaS2CKRrq27OuMtE4+W2yGhRQKtY1rTOqY1cdFxevG8GdOkoVQTklucy4Z9G9h9cDc5h3LILc4ltziXnOKj44fLDx+zXJRE0Ta2LcmxySTHJdOjTQ+SY5NJik0iqWVSZRJo27ItSbFJJLZIJCYqxoM9VOFOk4ZSYajcX853+79j/b71fJv/Levz17N+33pyi3Or1GvTog3t49qT0iqFoR2GOuNxKZVDu9h2JMclk9QySZt3VIPQpKGUh4wx5JXkkVWQRda+LLIKstiwbwMb922kpLwEgGhfNH2S+nBOl3Po364//dr1o2vrrqTEpdAiqoXHe6AijSYNpRpJQUkBGws2sqlgk5Mk7FB4uLCyTlLLJE5uezLX97veSRBt+9ErsZc2FamwoUlDqQZ2sPRglTOHisHdtJQQk0DvpN5cctIl9EnqQ5+kPvRO6k1ybLJeRFZhTZOGUvWw99BeMnMzWZ27mg37NpC1L4udB492WhAXHUfvxN6c2/XcKsmhY6uOmhxUk6RJQ6kgFR0pYk3emsokkZmbyd5DewGIlmh6JvVkaIehfC/pe06CaNuHrq276gVo1axo0lCqBruKdrF8z3LSd6ezKmcVWwq3VP6orUdCD9I6pjEkZQiDUwbTv11/YqNjPY5YqdDTpKGUtaNoB8t3O0kifU86O4p2AM5trUM7DGVMzzEMSRnCoORBJMUmeRytUt7QpKEiVuHhQj7N/pSvdn1F+u70ymsRSS2TGN5xOLcOuJXTO51O37Z9tYlJKUuThooo2Qey+Xj7x3y8/WNW7FlBuSmnbcu2pHVK4/ZBt5PWKY0+SX00SShVA00aqlkzxrA2by0fbf+Ij7d/zMZ9GwHok9SHHw7+IRd2v5BBKYM0SSgVJE0aqllan7+eOVlzWLR1EXuL9+ITH8M6DOOnaT/lwu4X0r1N9xOvRCl1DE0aqtkoPFzIfzf/l3ez3mVd/jpifDGM7DaSi3pcxMiuI/XitVINQJOGatLK/eUs3bWUOVlzWLxtMaX+Uga0G8AjZzzCFb2uILFlotchKtWsaNJQTdLOop3M3jibuVlz2XNoD4ktE7mh3w2M6zOO/u36ex2eUs2WJg3VpGzbv42XMl/iP5v+gx8/Z3c5m5+d/jMu6H6B9viqVCPQpKGahM0Fm5mZOZP5W+YT44vhhn43MH7QeDq37ux1aEpFFE0aKqytz1/PzIyZLPpuEbHRsdw24DbGDx5PSlyK16EpFZE0aaiwtCZvDTNXzeSj7R8RHxPPHUPu4LaBt9Eutp3XoSkV0TRpqLCyuWAzT694miXbl5DQIoF7Tr2HWwbcondBKRUmNGmosJBzKIfnVz3POxvfIS46jklDJ/H9Ad8noUWC16EppVw0aShPHSw9yKw1s3h1zauU+ku5uf/NTDxlojZDKRWmNGkoT5T6S5m9YTYvrHqB/JJ8Lku9jAdOe0C791AqzGnSUI3KGMPibYt5ZsUzbN2/leEdhzP9oukMaT/E69CUUkHQpKEaTda+LH6z9Dek70mnV2Ivpl80nZHdRuqzspVqQjRpqJA7VHqIGRkzeG3Na7SKacWjZz3KtX2vJdqnbz+lmhr9V6tC6qNtHzFt2TR2HdzF2N5jeSjtIb3IrVQTpklDhcSOoh1MWzqNJdlL6JPUh1mjZzG843Cvw1JK1ZMmDdWgSstLmbVmFjMzZiIi/GT4T7hl4C3E+GK8Dk0p1QA0aagGs3LvSh778jG2FG5hVI9RTD5jMp3iO3kdllKqAWnSUPXmN35mrZnFsyuepVN8J567+DlGdhvpdVhKqRDweblxERktIutFJEtEpgSYP15EckRkpR3u9CJOVbP8knzuXXwvT3/9NBf3uJh/XfUvTRhKNWOenWmISBTwHHAJkA0sF5F5xpi11ar+0xgzqdEDVCeUvjudyZ9OpuBwAb8885fc0O8G/c2FUs2cl81TZwBZxpjNACLyFjAWqJ40VJgp95fzUuZLPL/qebondOe5Uc/pI1aVihBeJo2uwHbXdDZwZoB614nISGAD8KAxZnuAOqqR5BbnMuWzKSzdtZTLe17OYyMeIz4m3uuwlFKNxMukEagdw1Sb/g/wpjHmsIjcDbwKXHTMikQmAhMBevTo0dBxKuurXV8x5dMpHCw9yONnP841fa7R5iilIoyXF8KzAXeXpt2Ane4Kxpg8Y8xhO/lXIOCvw4wxM40xacaYtPbt24ck2EhmjOGlzJeY+MFEElsm8sYVb3Bt32s1YSgVgbw801gO9BWRnsAO4Cbg++4KItLZGLPLTl4NrGvcEFWpv5Rff/Vr3tn4DmNSxzD17Km0imnldVhKKY94ljSMMWUiMglYCEQBrxhj1ojI/wLpxph5wP0icjVQBuQD472KNxIdOHKAnyz5Cf+36/+4a8hdTDptEj7x9C5tpZTHxJjqlxGatrS0NJOenu51GE3erqJd/Hjxj9lauJXHRjzGNX2v8TokpVQIicjXxpi0E9XTX4SrY6zNW8ukxZMoLivm+VHPM6LLCK9DUkqFCW1rUFV8sv0Txi8YT7QvmtfGvKYJQylVhSYNVemNdW9w/8f30zOxJ69f/jp92/b1OiSlVJjR5ilFub+cP6T/gX+s+wcXdLuAJ0c+qXdIKaUC0qQR4YwxPPHVE8zeOJtbBtzCT9N+SpQvyuuwlFJhSpNGhHv2m2eZvXE2dw25i/uH3e91OEqpMKfXNCLYa2te46XMl7j+5Ou577T7vA5HKdUEaNKIUP/Z9B9+n/57LjnpEn5x5i+0SxClVFA0aUSgT7M/5dEvHuXMTmcy7bxpeg1DKRU0TRoR5pu93/CTJT+hX7t+PHPRM7SIauF1SEqpJkSTRgTZsG8D9y6+l07xnXhh1Av6HAylVK1p0ogQO4p2cPeiu4mLimPGJTNoF9vO65CUUk2Q3nIbAfKK85j4wUQOlx/m1dGv0qV1F69DUko1UZo0mrmiI0Xc8+E97D20l79e+lf6tO3jdUhKqSZMk0YzZozh8f97nA37NvCXi/7C0A5DvQ5JKdXE6TWNZuzdrHdZsHUBk06bxHndzvM6HKVUM6BJo5naXLCZ3y37HWd2OpMJgyZ4HY5SqpnQpNEMHS4/zM8+/RmxUbH89rzf6o/3lFINRq9pNENPf/006/et57mLn6NDqw5eh6OUakb0TKOZWbJ9Ca+ve51bB9zKyG4jvQ5HKdXMaNJoRvYc3MOjXzxK/3b9eXD4g16Ho5RqhjRpNBPl/nIe+fwRDpcf5qmRT2mfUkqpkNCk0Uy8vPpllu9ezs/P/Dk9E3t6HY5SqpnSpNEMrNy7kudXPs+YnmMY23us1+EopZoxTRpN3P4j+5n86WQ6xXfi0bMe1YcpKaVCSm+5bcKMMTz+5ePsPbSXV8e8SkKLBK9DUko1c3qm0YTN2zSPD777gEmnTeKU9qd4HY5SKgJo0miicotzeWr5U5zW4TQmDNZuQpRSjUOTRhP1u6W/o7ismKlnT8Un+mdUSjUO/bRpghZvW8wH333APafeQ6/EXl6Ho5SKIJo0mpj9R/bzm69+Q7+2/Rg/eLzX4SilIswJk4aITBKRto0RjDqxP6X/ibySPB4/53FifDFeh6OUijDBnGl0ApaLyNsiMlr0hwCeWbprKbM3zub2QbczKHmQ1+EopSLQCZOGMeaXQF/gZWA8sFFEfisivUMcm3IpLitm6pdT6ZHQgx+f+mOvw1FKRaigrmkYYwyw2w5lQFvg3yLyVH02bs9c1otIlohMCTC/pYj8085fKiKp9dleU/b8yufJLspm6tlTiY2O9TocpVSECuaaxv0i8jXwFPAFMMQYcw8wHLiurhsWkSjgOWAMMBC4WUQGVqt2B7DPGNMHeBp4sq7ba8pW567mtbWvcf3J13N6p9O9DkcpFcGC6UYkBbjWGPOdu9AY4xeRK+ux7TOALGPMZgAReQsYC6x11RkLTLXj/wami4jYM5+IUFpeymNfPkZKbIo+I0Mp5blgmqfeB/IrJkQkQUTOBDDGrKvHtrsC213T2bYsYB1jTBlQCCRXX5GITBSRdBFJz8nJqUdI4eeV1a+wcd9GHh3xqPYtpZTyXDBJ4wWgyDV90JbVV6C7sKqfQQRTB2PMTGNMmjEmrX379g0QWnjYXLCZGRkzGJM6hgu6X+B1OEopFVTSqNIcZIzx0zC942YD3V3T3YCdNdURkWggEddZT3PmN35+9eWvaBXTislnTPY6HKWUAoJLGpvtxfAYOzwAbG6AbS8H+opITxFpAdwEzKtWZx5wux3/HvBRpFzP+O/m/7IyZyWTT59MctwxLXJKKeWJYJLG3cDZwA6cb/5nAhPru2F7jWISsBBYB7xtjFkjIv8rIlfbai8DySKSBTwEHHNbbnNU7i9nZsZM+rXtx5W96nOvgVJKNawTNjMZY/binAU0OGPM+zgX2t1lj7nGS4DrQ7HtcLbou0Vs3b+VP57/R30Sn1IqrJwwaYhILM7vJQYBlb8qM8b8MIRxRSy/8TMjYwa9Ensx6qRRXoejlFJVBNM89Xec/qcuAz7BuWB9IJRBRbKPt39MVkEWd51ylz4nQykVdoL5VOpjjHkUOGiMeRW4AhgS2rAikzGGGatm0D2hO6NTR3sdjlJKHSOYpFFqXwtEZDDOba+pIYsogn2+43PW5a/jriF3Ee1riLualVKqYQXzyTTTPk/jlzi3wLYGHg1pVBHIGMOMjBl0ju/Mlb31jimlVHg6btIQER+w3xizD/gU0GeLhsjS3UtZlbOKX575S324klIqbB23ecr++ntSI8US0WZmzKRDXAfG9R3ndShKKVWjYK5pLBKRh0Wku4i0qxhCHlkEWbFnBct3L2fC4Am0jGrpdThKKVWjYK5pVPwe415XmUGbqhrMjIwZtIttx3Un1/nxJEop1SiC+UV4z8YIJFJl5mTy5c4veXD4g8RFx3kdjlJKHVcwvwj/QaByY8xrDR9O5JmZMZPElonc2O9Gr0NRSqkTCqZ5yv180VjgYmAFoEmjnr7N/5Yl2Uu4d+i9xMfEex2OUkqdUDDNU/e5p0UkEadrEVVPMzNm0jqmNd8f8H2vQ1FKqaDUpXOjQ0Dfhg4k0mwq2MSH333Izf1vpk2LNl6Ho5RSQQnmmsZ/OPqIVR8wEHg7lEFFgr9m/pXY6FhuG3ib16EopVTQgrmm8QfXeBnwnTEmO0TxRITtB7Yzf8t8fjDwB7SNbet1OEopFbRgksY2YJd9IBIiEiciqcaYrSGNrBl7Z+M7ANw64FaPI1FKqdoJ5prGvwC/a7rclqk6KPOXMTdrLud1PY+O8R29DkcppWolmKQRbYw5UjFhx1uELqTm7YsdX5BTnMM1fa7xOhSllKq1YJJGjohcXTEhImOB3NCF1LzNyZpDu9h2jOw+0utQlFKq1oK5pnE38LqITLfT2UDAX4mr48stzuWT7Z9w68BbtftzpVSTFMyP+zYBZ4lIa0CMMfp88Dp6b9N7lJkyrumrTVNKqabphM1TIvJbEUkyxhQZYw6ISFsR+XVjBNecGGN4J+sdhrYfSq9E7SBYKdU0BXNNY4wxpqBiwj7F7/LQhdQ8rcpZxZbCLXqWoZRq0oJJGlEiUvlkIBGJA/RJQbX0zsZ3iIuO47LUy7wORSml6iyYC+H/ABaLyN/s9ATg1dCF1PwcKj3Egq0LGJ06WnuzVUo1acFcCH9KRDKAUYAAC4CTQh1Yc7Jw60KKy4q5tu+1XoeilFL1Emwvt7txfhV+Hc7zNNaFLKJm6J2N79AzsSentj/V61CUUqpeajzTEJGTgZuAm4E84J84t9xe2EixNQubCzazMmclDw1/CBHxOhyllKqX4zVPfQt8BlxljMkCEJEHGyWqZmRO1hyiJZqrel/ldShKKVVvx2ueug6nWepjEfmriFyMc01DBanUX8q8TfMY2W0kKXEpXoejlFL1VmPSMMbMMcbcCPQHlgAPAh1F5AURubSR4mvSPs0W7KHUAAAV9klEQVT+lPySfL0ArpRqNk54IdwYc9AY87ox5kqgG7ASmBLyyJqBORvn0D6uPed0PcfrUJRSqkHU6hnhxph8Y8wMY8xF9dmoiLQTkUUistG+Bnx8nYiUi8hKO8yrzzYb295De/lsx2dc3ftqon3B/BxGKaXCX62SRgOaAiw2xvQFFlPzmUuxMWaoHa6uoU5YmrdpHn7j125DlFLNildJYyxHf1X+KjDOozhCwhjDnI1zGN5xOCe10d9BKqWaD6+SRkdjzC4A+9qhhnqxIpIuIl+JSI2JRUQm2nrpOTk5oYi3Vr7e8zXbDmzTC+BKqWYnZI3tIvIh0CnArF/UYjU9jDE7RaQX8JGIZNrne1RhjJkJzARIS0szdQq4Ac3JmkN8TDyjeozyOhSllGpQIUsaxpgaPzFFZI+IdDbG7BKRzsDeGtax075uFpElwGnAMUkjnBQdKeKDrR9wZe8raRXTyutwlFKqQXnVPDUPuN2O3w7MrV7BPuyppR1PAc4B1jZahHW0eNtiSspLGNt7rNehKKVUg/MqaUwDLhGRjcAldhoRSRORl2ydAUC6iKwCPgamGWPCPmks2LqALvFdtHNCpVSz5MkPCIwxeTi95VYvTwfutONfAkMaObR6KSgp4KudX3HboNu0c0KlVLPk1ZlGs/Thtg8pM2WMTh3tdShKKRUSmjQa0IKtC+iR0IMB7QZ4HYpSSoWEJo0Gklucy/Ldy7ks9TJtmlJKNVuaNBrIh999iN/4GdNzjNehKKVUyGjSaCDzt8ynd2Jv+rbt63UoSikVMpo0GsCeg3v4Zu83XNbzMq9DUUqpkNKk0QA++O4DDEbvmlJKNXuaNBrAgq0L6N+uPz0Te3odilJKhZQmjXraUbSDjJwMLkvVpimlVPOnSaOeFm5dCKBJQykVETRp1NOCLQsYnDyY7gndvQ5FKaVCTpNGPWzbv411+esY3VMvgCulIoMmjXpYsHUBoE1TSqnIoUmjHuZvmc9pHU6jU3ygBxQqpVTzo0mjjjYVbCKrIEvPMpRSEUWTRh0t2LoAn/g0aSilIoomjTowxrBgywLSOqaREpfidThKKdVoNGnUwfp969m6f6ueZSilIo4mjTpYsGUBURLFJSdd4nUoSinVqDRp1JIxhgVbF3BW57NoG9vW63CUUqpRadKopTV5a9hRtEObppRSEUmTRi3N3zKfaF80F/W4yOtQlFKq0UV7HUBT4jd+Fm5dyDldziGxZaLX4SilGkBpaSnZ2dmUlJR4HUqjiI2NpVu3bsTExNRpeU0atbBx30b2HNrDfafd53UoSqkGkp2dTUJCAqmpqYiI1+GElDGGvLw8srOz6dmzbs//0eapWliVswqAYR2GeRyJUqqhlJSUkJyc3OwTBoCIkJycXK+zKk0atZCZm0nblm3pltDN61CUUg0oEhJGhfruqyaNWsjMyWRwyuCIeoMppZSbJo0gFR0pYnPhZoa0H+J1KEqpZiQvL4+hQ4cydOhQOnXqRNeuXSunjxw5EtQ6JkyYwPr160McqUMvhAdpdd5qDIZTU071OhSlVDOSnJzMypUrAZg6dSqtW7fm4YcfrlLHGIMxBp8v8Pf8v/3tbyGPs4ImjSBl5mQCMLj9YI8jUUqFyuP/WcPanfsbdJ0Du7ThV1cNqvVyWVlZjBs3jnPPPZelS5fy3nvv8fjjj7NixQqKi4u58cYbeeyxxwA499xzmT59OoMHDyYlJYW7776b+fPn06pVK+bOnUuHDh0abH+0eSpIGbkZpLZJpU2LNl6HopSKEGvXruWOO+7gm2++oWvXrkybNo309HRWrVrFokWLWLt27THLFBYWcv7557Nq1SpGjBjBK6+80qAx6ZlGEIwxZORkcG7Xc70ORSkVQnU5Iwil3r17c/rpp1dOv/nmm7z88suUlZWxc+dO1q5dy8CBA6ssExcXx5gxYwAYPnw4n332WYPGpEkjCDsP7iS/JJ8hKXoRXCnVeOLj4yvHN27cyDPPPMOyZctISkri1ltvDfh7ixYtWlSOR0VFUVZW1qAxedI8JSLXi8gaEfGLSNpx6o0WkfUikiUiUxozRreK6xl655RSyiv79+8nISGBNm3asGvXLhYuXOhJHF6daawGrgVm1FRBRKKA54BLgGxguYjMM8Yc24gXYhm5GbSMasnJbU9u7E0rpRQAw4YNY+DAgQwePJhevXpxzjnneBKHGGM82TCAiCwBHjbGpAeYNwKYaoy5zE4/AmCM+d3x1pmWlmbS049ZXb3c9v5tAPz98r836HqVUt5bt24dAwYM8DqMRhVon0Xka2NMjS0/FcL57qmuwHbXdLYta1Sl/lLW5a/TpimllCKEzVMi8iHQKcCsXxhj5gazigBlAU+LRGQiMBGgR48eQccYjA37NnC4/DCntD+lQderlFJNUciShjFmVD1XkQ10d013A3bWsK2ZwExwmqfqud0qKi6Cn5KiSUMppcK5eWo50FdEeopIC+AmYF5jB5GZm0lybDKd4zs39qaVUirseHXL7TUikg2MAP4rIgtteRcReR/AGFMGTAIWAuuAt40xaxo71oycDIa0H6I92yqlFB7dcmuMmQPMCVC+E7jcNf0+8H4jhlZF4eFCtu7fytW9r/YqBKWUCivh3DzludW5qwH9UZ9SKnQaomt0gFdeeYXdu3eHMFKHdiNyHBm5GQjC4GTt2VYpFRrBdI0ejFdeeYVhw4bRqVOgm1YbjiaN48jMyaRXYi9at2jtdShKqcYwfwrszmzYdXYaAmOm1WnRV199leeee44jR45w9tlnM336dPx+PxMmTGDlypUYY5g4cSIdO3Zk5cqV3HjjjcTFxbFs2bIqfVA1JE0aNTDGkJmbyYXdL/Q6FKVUBFq9ejVz5szhyy+/JDo6mokTJ/LWW2/Ru3dvcnNzycx0kltBQQFJSUn85S9/Yfr06QwdOjSkcWnSqEH2gWwKDhfo9QylIkkdzwhC4cMPP2T58uWkpTk9exQXF9O9e3cuu+wy1q9fzwMPPMDll1/OpZde2qhxadKoQUZuBqA/6lNKecMYww9/+EOeeOKJY+ZlZGQwf/58nn32WWbPns3MmTMbLS69e6oGmbmZxEXH0Tupt9ehKKUi0KhRo3j77bfJzc0FnLustm3bRk5ODsYYrr/++srHvwIkJCRw4MCBkMelZxo1yMjJYGDyQKJ9eoiUUo1vyJAh/OpXv2LUqFH4/X5iYmJ48cUXiYqK4o477sAYg4jw5JNPAjBhwgTuvPPOkF8I97Rr9FBoiK7Rj5Qf4aw3zuLWAbfyUNpDDRSZUiocadfojubQNbpnvs3/llJ/qV4EV0qpajRpBJCZax/vqs8EV0qpKjRpBJCRk0GHVh3oFB/aX1YqpVRTo0kjgMzcTL3VVimlAtCkUc2+kn1sP7Bdr2copVQAmjSq0esZSilVM00a1WTmZuITH4OSB3kdilIqAtS2a/T8/HxefPHFE663rKyMpKSkBo9Xf7lWTUZOBn2S+tAqppXXoSilIkBtu0avSBp33313Y4VYhSYNF7/xk5mbyaUnNW4HYEqp8PDksif5Nv/bBl1n/3b9mXzG5Dot+9RTT/Haa68B8KMf/Yj77ruPKVOmsH79eoYOHcro0aP5+c9/zrhx4ygoKKCsrIzf/va3XHnllQ25C1Vo0nD5bv93HDhygFPa651TSilvLVu2jNdff51ly5ZRXl7OGWecwfnnn8+0adPIysqqPDspLS1l7ty5JCQksHfvXs455xxNGo2l4iK43m6rVGSq6xlBKHz22Wdcd911tGrlNJWPGzeOzz///Jiu0I0xTJ48mc8//xyfz8f27dvJzc0NyfUM0KRRRUZOBvEx8fRM7Ol1KEqpCBdsv4CvvfYahYWFrFixgujoaLp160ZJSUnI4tK7p1wyczMZnDyYKF+U16EopSLcyJEjmTNnDsXFxRQVFTF37lzOO++8Y7pALywspEOHDkRHR7No0SJ27NgR0rj0TMMqKSthQ/4Gxg8e73UoSinFGWecwc0338zpp58OwD333MOQIc7vx9LS0hgyZAhXXHEFDz30EFdddRVpaWkMGzaMvn37hjQu7Rrdyi3O5anlT3Ft32s5q/NZIYhMKRWOtGt0R7Bdo+uZhpUSl8JTI5/yOgyllAprek1DKaVU0DRpKKUiXnNrpj+e+u6rJg2lVESLjY0lLy8vIhKHMYa8vDxiY2PrvA69pqGUimjdunUjOzubnJwcr0NpFLGxsXTr1q3Oy2vSUEpFtJiYGHr21B/0Bkubp5RSSgVNk4ZSSqmgadJQSikVtGb3i3ARyQG+C7J6CpAbwnBCQWMOvaYWL2jMjaU5x3ySMab9iSo1u6RRGyKSHszP5sOJxhx6TS1e0Jgbi8aszVNKKaVqQZOGUkqpoEV60pjpdQB1oDGHXlOLFzTmxhLxMUf0NQ2llFK1E+lnGkoppWpBk4ZSSqmgRWzSEJHRIrJeRLJEZIrX8VQQkVdEZK+IrHaVtRORRSKy0b62teUiIs/afcgQkWEexNtdRD4WkXUiskZEHmgCMceKyDIRWWVjftyW9xSRpTbmf4pIC1ve0k5n2fmpjR2zjSNKRL4RkfeaSLxbRSRTRFaKSLotC9v3hY0jSUT+LSLf2vf0iHCOWUT62eNbMewXkf8JaczGmIgbgChgE9ALaAGsAgZ6HZeNbSQwDFjtKnsKmGLHpwBP2vHLgfmAAGcBSz2ItzMwzI4nABuAgWEeswCt7XgMsNTG8jZwky1/EbjHjv8YeNGO3wT806P3xkPAG8B7djrc490KpFQrC9v3hY3jVeBOO94CSAr3mF2xRwG7gZNCGbNnO+jxwR0BLHRNPwI84nVcrnhSqyWN9UBnO94ZWG/HZwA3B6rnYexzgUuaSsxAK2AFcCbOr2ajq79HgIXACDsebetJI8fZDVgMXAS8Z//Rh228dtuBkkbYvi+ANsCW6scqnGOuFuelwBehjjlSm6e6Attd09m2LFx1NMbsArCvHWx5WO2HbQY5Deebe1jHbJt6VgJ7gUU4Z54FxpiyAHFVxmznFwLJjRsxfwZ+BvjtdDLhHS+AAT4Qka9FZKItC+f3RS8gB/ibbQZ8SUTiCe+Y3W4C3rTjIYs5UpOGBChrivceh81+iEhrYDbwP8aY/cerGqCs0WM2xpQbY4bifIM/AxgQqJp99TRmEbkS2GuM+dpdHKBqWMTrco4xZhgwBrhXREYep244xByN0zT8gjHmNOAgTtNOTcIhZgDs9ayrgX+dqGqAslrFHKlJIxvo7pruBuz0KJZg7BGRzgD2da8tD4v9EJEYnITxujHmHVsc1jFXMMYUAEtw2neTRKTiwWTuuCpjtvMTgfxGDPMc4GoR2Qq8hdNE9ecwjhcAY8xO+7oXmIOTnMP5fZENZBtjltrpf+MkkXCOucIYYIUxZo+dDlnMkZo0lgN97d0nLXBO6+Z5HNPxzANut+O341w3qCj/gb0j4iygsOKUtLGIiAAvA+uMMX9yzQrnmNuLSJIdjwNGAeuAj4Hv1RBzxb58D/jI2AbhxmCMecQY080Yk4rzXv3IGHNLuMYLICLxIpJQMY7T3r6aMH5fGGN2A9tFpJ8tuhhYG84xu9zM0aYpCGXMXl208XrAuYtgA05b9i+8jscV15vALqAU51vBHTjt0YuBjfa1na0rwHN2HzKBNA/iPRfn9DYDWGmHy8M85lOAb2zMq4HHbHkvYBmQhXOa39KWx9rpLDu/l4fvjws4evdU2MZrY1tlhzUV/8bC+X1h4xgKpNv3xrtA2yYQcysgD0h0lYUsZu1GRCmlVNAitXlKKaVUHWjSUEopFTRNGkoppYKmSUMppVTQNGkopZQKmiYN1ShExIjIH13TD4vI1AZa9ywR+d6Ja9Z7O9fbnk8/rlaeKq5eiYNYzzgRGViPOFJF5PvHmVdcrefTFg25DRXZNGmoxnIYuFZEUrwOxE1EompR/Q7gx8aYC+u52XE4PQHXVSpwvA/0TcaYoa7hSAi2EVAtj6dqgjRpqMZShvOs4gerz6h+piAiRfb1AhH5RETeFpENIjJNRG4R51kYmSLS27WaUSLyma13pV0+SkR+LyLL7bMDfuRa78ci8gbOD5yqx3OzXf9qEXnSlj2G80PGF0Xk98HssIjcZbe9SkRmi0grETkbp4+g39uzgN52WGA79vtMRPq7jsuzIvKliGx2HaNpwHl2+WOOZw2xxIvzrJbl4nTGN9aWp9ptrrDD2YG2ISLjRWS6a33vicgFdrxIRP5XRJYCI0RkuP27fS0iC+Vodxb3i8ha+7d4K5i4VRjy4heMOkTeABThdD29FacvpIeBqXbeLOB77rr29QKgAKdr55bADuBxO+8B4M+u5RfgfAnqi/NL+lhgIvBLW6clzi99e9r1HgR6BoizC7ANaI/Tgd1HwDg7bwkBfkFLta7sXeXJrvFfA/fVsL+Lgb52/Eycbj8q6v3L7tdAIMt1XN6r4TinAsUc/XX+c7b8t8CtdjwJpzeEeJxfE8fa8r5AeqBtAOOB6a7p94AL7LgBbrDjMcCXQHs7fSPwih3fydFfrSd5/Z7UoW5DRWdnSoWcMWa/iLwG3I/zwRaM5cb2jSMim4APbHkm4G4metsY4wc2ishmoD9Of0enuL6hJ+J8MB4BlhljtgTY3unAEmNMjt3m6zgPxno3yHjdBovIr3E+pFvjPOeiCnF6Bz4b+JdIZQekLV1V3rX7tVZEOga53U3G6cHX7VKcTg8fttOxQA+cD/LpIjIUKAdODnIbbuU4HVYC9AMGA4vs/kThdIsDTtccr4vIu9TteKowoElDNbY/4zz06G+usjJsU6k4nzTuC7eHXeN+17Sfqu/f6v3hGJx+du4zxlT5sLbNKgdriC9Q19F1NQvnLGWViIzH+fZenQ/nuRjVP+QruPe/PrEJcJ0xZn2VQudmhD3AqTaWkhqWr/wbWbGu8RJjTLlrO2uMMSMCrOMKnAR8NfCoiAwyR58HopoIvaahGpUxJh/nMaV3uIq3AsPt+FicJo7aul5EfPY6Ry+cJ5ItBO4Rp+t2RORkcXpcPZ6lwPkikmIv6t4MfFKHeMB5/O0uu/1bXOUH7DyM8+yRLSJyvY1RROTUE6y3cvlaWAjcZ5MyInKaLU8EdtmzmdtwzgwCbWMrMNQe4+443ZwHsh5oLyIj7HZiRGSQiPiA7saYj3EeJlVx9qWaGE0aygt/BNx3Uf0V54N6GU6bfk1nAcezHufDfT5wtzGmBHgJp2vrFeLcEjuDE5xd26awR3C6HV+F84yCucdbxuonItmu4XrgUZwktAj41lX3LeCn9oJ0b5yEcoeIVPQIO/YE28oAyuwF9qAuhANP4CTjDHssnrDlzwO3i8hXOE1TFce++ja+wHkUaibwB5yzxWMY506t7wFP2v1ZidP8FgX8Q0QycXoYfto4zzJRTYz2cquUUipoeqahlFIqaJo0lFJKBU2ThlJKqaBp0lBKKRU0TRpKKaWCpklDKaVU0DRpKKWUCtr/AzuCBdZ1kVzJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a06007cf8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs_train = []\n",
    "sum_errs_test = []\n",
    "sum_all_errs = []\n",
    "\n",
    "\n",
    "\n",
    "#Decomposition for test data\n",
    "row_idx = user_item_train.index.isin(test_idx)\n",
    "col_idx = user_item_train.columns.isin(test_arts)\n",
    "u_test = u_train[row_idx, :]\n",
    "vt_test = vt_train[:, col_idx]\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s_train[:k]), u_train[:, :k], vt_train[:k, :]\n",
    "    u_test_new, vt_test_new = u_test[:, :k], vt_test[:k, :]\n",
    "    \n",
    "    # take dot product using both train and test data\n",
    "    user_item_train_preds = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    user_item_test_preds  = np.around(np.dot(np.dot(u_test_new, s_new), vt_test_new))    \n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs_train = np.subtract(user_item_train, user_item_train_preds)\n",
    "    diffs_test = np.subtract(user_item_test.loc[predictable_users,:], user_item_test_preds)    \n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err_train = np.sum(np.sum(np.abs(diffs_train)))\n",
    "    err_test = np.sum(np.sum(np.abs(diffs_test)))\n",
    "    sum_errs_train.append(err_train)\n",
    "    sum_errs_test.append(err_test)\n",
    "    \n",
    "    total_error = np.add(err_train, err_test)\n",
    "    sum_all_errs.append(total_error)    \n",
    "    \n",
    "\n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs_train)/(user_item_train_preds.shape[0]*user_item_train_preds.shape[1]), \n",
    "         label='Train')\n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs_test)/ (user_item_test_preds.shape[0]*user_item_test_preds.shape[1]),\n",
    "         label='Test')\n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_all_errs)/ (user_item_test_preds.shape[0]*user_item_test_preds.shape[1]),label='Total')\n",
    "plt.xlabel('Number of Latent Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Number of Latent Features') \n",
    "plt.legend()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`6.` Use the cell below to comment on the results you found in the previous question. Given the circumstances of your results, discuss what you might do to determine if the recommendations you make with any of the above recommendation systems are an improvement to how users currently find articles? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating some metrics such as the Root Mean Square Errors (RMSE) between the actual and predicted values could be used to measure the efficacy of the recommendations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_id  0     2         4        8     9         12    14        15    \\\n",
      "user_id                                                                     \n",
      "2917         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "3024         0.0   0.0  0.000000  0.00000   0.0  1.000000   0.0  0.000000   \n",
      "3093         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "3193         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "3527         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "3532         0.0   0.0  0.000000  0.92582   0.0  1.000000   0.0  0.000000   \n",
      "3684         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "3740         0.0   0.0  0.000000  0.00000   0.0  1.000000   0.0  0.000000   \n",
      "3777         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "3801         0.0   0.0  0.000000  0.00000   0.0  0.447214   0.0  0.000000   \n",
      "3968         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.792825   \n",
      "3989         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "3990         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "3998         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "4002         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "4204         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "4231         0.0   0.0  0.676123  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "4274         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "4293         0.0   0.0  0.000000  0.00000   0.0  0.000000   0.0  0.000000   \n",
      "4487         0.0   0.0  0.000000  0.92582   0.0  0.000000   0.0  0.000000   \n",
      "\n",
      "article_id      16    18    ...       1432      1433  1434  1435      1436  \\\n",
      "user_id                     ...                                              \n",
      "2917        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.000000   \n",
      "3024        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.985611   \n",
      "3093        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  1.000000   \n",
      "3193        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.000000   \n",
      "3527        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.000000   \n",
      "3532        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.000000   \n",
      "3684        0.000000   0.0  ...   0.000000  0.956183   0.0   0.0  0.000000   \n",
      "3740        0.910259   0.0  ...   0.000000  0.000000   0.0   0.0  0.239046   \n",
      "3777        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.000000   \n",
      "3801        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.971008   \n",
      "3968        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.000000   \n",
      "3989        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.000000   \n",
      "3990        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.000000   \n",
      "3998        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.000000   \n",
      "4002        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.000000   \n",
      "4204        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.985611   \n",
      "4231        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  1.000000   \n",
      "4274        0.000000   0.0  ...   0.985611  0.000000   0.0   0.0  0.000000   \n",
      "4293        0.000000   0.0  ...   1.000000  0.000000   0.0   0.0  0.000000   \n",
      "4487        0.000000   0.0  ...   0.000000  0.000000   0.0   0.0  0.000000   \n",
      "\n",
      "article_id  1437  1439  1440  1441  1443  \n",
      "user_id                                   \n",
      "2917         0.0   0.0   0.0   0.0   0.0  \n",
      "3024         0.0   0.0   0.0   0.0   0.0  \n",
      "3093         0.0   0.0   0.0   0.0   0.0  \n",
      "3193         0.0   0.0   0.0   0.0   0.0  \n",
      "3527         0.0   0.0   0.0   0.0   0.0  \n",
      "3532         0.0   0.0   0.0   0.0   0.0  \n",
      "3684         0.0   0.0   0.0   0.0   0.0  \n",
      "3740         0.0   0.0   0.0   0.0   0.0  \n",
      "3777         0.0   0.0   0.0   0.0   0.0  \n",
      "3801         0.0   0.0   0.0   0.0   0.0  \n",
      "3968         0.0   0.0   0.0   0.0   0.0  \n",
      "3989         0.0   0.0   0.0   0.0   0.0  \n",
      "3990         0.0   0.0   0.0   0.0   0.0  \n",
      "3998         0.0   0.0   0.0   0.0   0.0  \n",
      "4002         0.0   0.0   0.0   0.0   0.0  \n",
      "4204         0.0   0.0   0.0   0.0   0.0  \n",
      "4231         0.0   0.0   0.0   0.0   0.0  \n",
      "4274         0.0   0.0   0.0   0.0   0.0  \n",
      "4293         0.0   0.0   0.0   0.0   0.0  \n",
      "4487         0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[20 rows x 574 columns]\n",
      "0.0346808017715\n"
     ]
    }
   ],
   "source": [
    "# Calculating the RMSE for the test data\n",
    "   \n",
    "sse = 0\n",
    "num_rated = 0\n",
    "row_idx = user_item_train.index.isin(test_idx)\n",
    "col_idx = user_item_train.columns.isin(test_arts)\n",
    "u_test = u_train[row_idx, :]\n",
    "vt_test = vt_train[:, col_idx]\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s_train[:k]), u_train[:, :k], vt_train[:k, :]\n",
    "    u_test_new, vt_test_new = u_test[:, :k], vt_test[:k, :]\n",
    "    \n",
    "    # take dot product using both train and test data\n",
    "    user_item_train_preds = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    user_item_test_preds  = np.around(np.dot(np.dot(u_test_new, s_new), vt_test_new))    \n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs_train = np.subtract(user_item_train, user_item_train_preds)\n",
    "    diffs_test = np.subtract(user_item_test.loc[predictable_users,:], user_item_test_preds)    \n",
    "    num_rated += 1\n",
    "    # total errors and keep track of them\n",
    "    sse+= diffs_test**2\n",
    "rmse = rmse = np.sqrt(sse/num_rated)\n",
    "print(rmse)\n",
    "rmse2 = np.sum(np.sum(rmse))/np.product(rmse.shape) \n",
    "print(rmse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The result above shows that the single value decomposition approach is very efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='conclusions'></a>\n",
    "### Extras/ Conclusion\n",
    "Using the workbook, we could now save the recommendations for each user, develop a class to make new predictions and update your results, and make a flask/dash/streamlit app to deploy the results.  \n",
    "\n",
    "####  Discussion about the results, as well as a method by which to test how well the recommendation engine is working in practice.\n",
    "\n",
    "In this project, four different ways of making recommendations were explored, namely:\n",
    "\n",
    "1. **Knowledge Based Recommendation**: This was achieved using these functions: get_top_articles(n, df=df) and get_top_article_ids(n, df=df). This recommendation approach recommends the the top n articles based on the number of interactions some users have had with the articles. The problem with this approach is that it does not care whether the recommended articles are those the user has used before or not. \n",
    "2. **User-User Based Collaborative Filtering**: This type was implemented using user_user_recs(user_id, m=10) and user_user_recs_part2(user_id, m=10) functions. This approach is better than the first type because it recommends articles that users have not read. However, it cannot recommend articles for new users even if they interacted with some articles.\n",
    "3. **Content Based Recommendation**: make_content_recs() function is used to get a dictionary of all the users and recommended articles for each user based on content (that is similarity of articles they had read in the past). The method is able to make recommendations to new users who have read an article or more in the database using articles that are similar. \n",
    "4. **Matrix Factorization Recommendation**: This was carried out using single value decomposition (SVD). This approach was able to evaluate the performance of the recommendation engine using some test data (new users). Evaluation showed high accuracy with low RMSEs. However, it could only make recommendations for users in test data who are are also in the train data and could make make recommendations for articles whose ids were not in the training dataset due to cold start problem. \n",
    "\n",
    "#### The best way to use this recommendation engine would be a combination of the four concepts above as follows:\n",
    "\n",
    "1. Check if a user exists or there is a new user who have an article id s/he had already read or is interested in:\n",
    "2. If a user exists in the training dataset, proceed with Matrix Factorization Technique to make recommendations. \n",
    "3. If a user is not in the training dataset and there is no article id of interaction perform knowledge based recommendation to recommend popular articles. \n",
    "4. If a user who does not exist in the training dataset presents an article id he had read or interested in, then a Content Based Recommendation should be used to make recommendations.\n",
    "5. If the article_id in 4 above does not exist in the training dataset, then knowledge based recommendation would be used to recommend most popular articles. \n",
    "\n",
    "####  Testing how well the recommendation engine is working in practice\n",
    "\n",
    "In order to check the relevance of the recommendation engine in increasing rate of subscriptions to the IBM articles as a result of getting recommendations of articles via our recemmendation engine it would be necessary to perform **A/B Testing**. This could be done by creating two groups, namely: **control group**(users of the IBM platform who would not get any recommendations via the recommendation engine) and the **experimental group** (users of the IBM platform who would get any recommendations via the recommendation engine). The Null Hypothesis would be to assume that there would be more subscriptions coming from the the experimental group than the control group. If the A/B test is run for a certain period of time, it could determine if there would be statistical signicance for deploying the recommendation engine or not. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Recommendations_with_IBM.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
